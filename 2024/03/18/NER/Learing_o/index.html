<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Learning_O代码梳理 | 奇冀の观猹录</title><meta name="keywords" content="NER"><meta name="author" content="奇冀"><meta name="copyright" content="奇冀"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Learning_O代码梳理"><meta name="application-name" content="Learning_O代码梳理"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="Learning_O代码梳理"><meta property="og:url" content="http://example.com/2024/03/18/NER/Learing_o/index.html"><meta property="og:site_name" content="奇冀の观猹录"><meta property="og:description" content="主函数 创建解释器，添加命令行参数 123parser &amp;#x3D; argparse.ArgumentParser()parser.add_argument(...)args &amp;#x3D; parser.parse_args() 设置随机数种子以及每个任务包含的的标签数量 12set_seed(args)per_ty"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://example.com/img/tu/img(52).jpg"><meta property="article:author" content="奇冀"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://example.com/img/tu/img(52).jpg"><meta name="description" content="主函数 创建解释器，添加命令行参数 123parser &amp;#x3D; argparse.ArgumentParser()parser.add_argument(...)args &amp;#x3D; parser.parse_args() 设置随机数种子以及每个任务包含的的标签数量 12set_seed(args)per_ty"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://example.com/2024/03/18/NER/Learing_o/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: undefined,
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎回来！"},
  LA51: {"enable":true,"ck":"3IH9y4LmRJtzItks","LingQueMonitorID":"3IH9oXLUn9kZ7Y15"},
  greetingBox: {"enable":true,"default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋, 宝贝","startTime":12,"endTime":14},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"19点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://twikoo.yydnas.cn/',
  commentBarrageConfig:undefined,
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: {"mode":"both","api":"https://img2color-go.vercel.app/api?img=","cover_change":true},
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🏠 智能家居小能手","🔨 设计开发一条龙","🤝 专修交互与设计","🏃 脚踏实地行动派","🧱 团队小组发动机","✨ 多彩生活记录者"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    simplehomepage: false,
    post: true
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":true,"limitCount":50,"languages":{"author":"作者: 奇冀","link":"链接: ","source":"来源: 奇冀の观猹录","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: true,
  shortcutKey: {"enable":true,"delay":100,"shiftDelay":200},
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '奇冀の观猹录',
  title: 'Learning_O代码梳理',
  postAI: '',
  pageFillDescription: '主函数, 创建解释器添加命令行参数, 设置随机数种子以及每个任务包含的的标签数量, 持续学习, 准备数据集, read_examples_from_file(), convert_examples_to_features(), load_and_cache_examples(), 从文件中加载样本特征, 提取features的属性并构建数据集, 返回该数据集, 工具函数, get_exemplar_means(), 1. 将每个样本按标签分类, 计算每个类别的原型, 返回包含每个类别原型的列表, get_support_encodings_and_labels(_total)(), 获取train_loadersupport_loadersupport_o_loader中的encodings和labels, 返回所有的encodings和labels, get_token_logits_and_labels, get_rehearsal_prototype(), 加载支持集以及它们的encodings和labels, 计算类别相似度, 返回类别相似度列表, 定义模型, MySftBertModel(), 初始化 init, 前向传播 forward, 3. 返回 loss features_enc features logits, 训练和评估模型, train_and_eval( ), 加载上一轮预训练的参数配置、模型和分词器, 获取训练集, 获取旧模型的特征, 训练模型, 在开发集上评估模型, 在测试集上进行预测, teacher_evaluate(), 根据不同模式设置数据集加载器, 评估模型, 用原型重新标记阈值重新标记旧实体类, 返回 logits_list out_label_new_list, evaluate (), 读取数据集, 获取支持数据集的embbedings和labels, 三种重新标记来自旧类别的O的策略, 使用原型重新标记, 使用最近邻重新标记, 使用原有模型重新标记, 保存预测结果, 预测结果, train(), 计算训练总步数t_total和训练轮数num_train_epochs, 配置优化器, 训练, 评估, 返回全局步数和平均损失, 分类器, NNClassification(), nn_classifier_dot_prototype(), get_top_emissions_with_th()主函数创建解释器添加命令行参数设置随机数种子以及每个任务包含的的标签数量持续学习迭代每个任务获取当前任务的标签集标签数量和设置如果是第一轮则加载模型否则加载上一轮模型训练和评价模型准备数据集从文件中加载样本特征如果存在则直接从该文件中加载特征否则先处理原始数据再加载特征提取的属性并构建数据集返回该数据集工具函数计算每个类别的原型即均值向量将每个样本按标签分类创建了一个字典包含了所有可能的类别索引每个类别对应一个空列表将每个样本按照标签分类存储在字典中计算每个类别的原型如果当前类别下没有样本则随机初始化一个与样本表示大小相同的张量作为该类别的原型如果有则计算当前类别的所有样本的的均值作为原型返回包含每个类别原型的列表获取支持集的和获取中的和获取中每个批次的和仅过滤掉标签为填充标记的部分同样的操作获取和中每个批次的和返回所有的和使用原有的预训练模型获取预测分数和输出标签加载支持集以及它们的和将归一化计算类别相似度迭代每个非标签的类别计算类别的样本之间的余弦相似度将对角线上的元素样本与自身的相似度设置为以避免将自身视为原型计算类别的类别相似度返回类别相似度列表定义模型初始化接受配置参数以及其他自定义参数设置每轮任务的类型数量设置特征维度设置隐藏状态的大小设置标签数量设置了分类器和投影头根据选择性地设置分类器的输出层设置分类器的概率根据不同模式设置线性分类器的不同输出维度对样本重新标记过设置不同的线性层或多层感知机前向传播提取特征调用原有的模型初步提取出样本的特征通过对进一步提取出样本的特征并归一化使用初步特征进行预测如果不是训练模式直接返回计算损失函数如果是第一轮训练如果不是第一轮训练整理新类别标签新类别样本的以及旧类别样本的模型的返回训练和评估模型加载上一轮预训练的参数配置模型和分词器创建模型配置模型类别和分词器类如果是第一轮则直接加载模型获取训练集顺序采样创建训练数据加载器获取旧模型的特征如果当前不是第一个任务则需要对老师模型进行评估创建一个新的分类器训练模型保存训练过程中得到的模型参数配置和分词器在开发集上评估模型对于每个检查点加载模型并进行评估在测试集上进行预测加载模型和分词器调用函数对测试集进行预测获取和结果以及预测的标签根据不同模式设置数据集加载器如果模式是则使用训练数集如果模式是则使用开发集评估模型将模型设置为评估模式使用函数获取每个的预测分数和输出标签对评估步骤计数以便跟踪已评估的批次数量将每个批次的分数添加到列表中用原型重新标记阈值重新标记旧实体类计算原型重新标记阈值和与每个样本的原型相似度最高的实体类别计算每个批次样本中原型相似度最大值所在的类别索引每个批次样本与每个类别的原型相似度的最大值根据原有模型预测的标签索引序列每个旧类别的原型重新标记阈值列表还未乘计算原型重新标记阈值根据不同的任务步骤来调整超参数重新标记旧实体类迭代每个迭代每个样本根据原型相似度预测的类别索引如果原型的相似度大于重新标记阈值并且预测的标签是旧实体类的标签则将该预测为这个旧实体类否则保持原始的标签不变返回读取数据集读取顺序采样数据集加载器获取支持数据集的和三种重新标记来自旧类别的的策略使用原型重新标记基于样本与原型之间的距离计算每个类别的原型计算原型重新标记阈值以及与原型的最高相似度利用计算循环迭代使用原有的模型获取每个批次的和如果是模式则去除掉当前样本的和再进行预测包含每个样本中原型相似度最大值所在的类别索引包含每个样本中原型相似度最大值所在的类别索引包含每个样本与每个类别的原型相似度的最大值每个旧类别的原型重新标记阈值列表还未乘使用最近邻重新标记基于样本与每个类别示例之间的距离使用原有模型重新标记作为前两种方法的参考标注保存预测结果将每个批次的预测结果追加到中并将作为参考标准的预测标签保存到中如果当前模式是模式还会保存第一次预测预测结果如果当前模式是模式那么函数直接将返回和如果使用的是线性分类器根据得出预测的最大和存储使用原有模型和使用自定义方法预测的标签字符串序列创建字典将标签的索引映射到相应标签的字符串名称输出评价指标结果使用库计算返回评价指标结果以及预测的标签序列计算训练总步数和训练轮数如果设置了训练最大步数则并计算否则根据计算配置优化器使用优化器使用了权重衰减和学习率调节器不需要衰减的参数训练迭代每一轮获取每个类别的类别相似度获取样本的和标签按批次遍历训练集中的数据将模型切换到训练模式如果不是第一轮训练如果是第一轮训练使用训练集的原始标签实体和的联合损失函数计算样本之间的余弦相似度分数存储样本之间大于实体阈值的余弦相似度分数选择类别相似度的中位数作为实体阈值用自定义的模型进行训练获取损失值如果设置了梯度累积步数则需要对损失值进行除以梯度累积步数以得到平均损失值更新参数后向传播如果达到梯度累计步数清除优化器中所有参数的梯度更新全局步数评估在开发集上评估模型性能保存模型及参数达到最大步数时停止训练关闭当前的迭代器返回全局步数和平均损失分类器根据原型进行重新标记来自旧实体类别的计算与每个类别原型的最大相似度将输入的表示重塑为二维张量并对其进行归一化处理将第一列真正的类别的相似度设为包含每个样本中原型相似度的最大值包含每个样本中原型相似度最大值所在的类别索引计算每个类别的原型重新标记阈值将重塑为二维张量并对其进行归一化处理计算每个类别原型与支持集中对应类别的样本的相似度沿着最后一个维度即特征维度寻找最小值并返回这些最小值以及对应的索引计算样本之间的余弦相似度排除样本的分数第二维排除样本与自身的分数筛选出大于实体阈值的分数返回',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-07-24 18:05:14',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/AssetsRepo" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/NLP-NER" title="智慧典藏(NLP-NER)"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="智慧典藏(NLP-NER)"/><span class="back-menu-item-text">智慧典藏(NLP-NER)</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/XDU-CS-lab" title="XDU-CS-lab"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="XDU-CS-lab"/><span class="back-menu-item-text">XDU-CS-lab</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">奇冀の观猹录</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"/><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于我</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/equipment/"><i class="anzhiyufont anzhiyu-icon-heartbeat faa-tada" style="font-size: 0.9em;"></i><span> 我的书屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://cdn.luogu.com.cn/upload/image_hosting/wyeaqekf.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://cdn.luogu.com.cn/upload/image_hosting/wyeaqekf.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.luogu.com.cn/upload/image_hosting/dqwj733b.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://cdn.luogu.com.cn/upload/image_hosting/dqwj733b.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">音乐</div><span class="author-content-item-title">灵魂的碰撞💥</span></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">5</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/02/"><span class="card-archive-list-date">二月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">14</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">十一月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div><div class="console-btn-item" id="consoleKeyboard" onclick="anzhiyu.keyboardToggle()" title="快捷键开关"><a class="keyboard-switch"><i class="anzhiyufont anzhiyu-icon-keyboard"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/NER/" itemprop="url">NER</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/NER/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>NER</span></a></span></div></div><h1 class="post-title" itemprop="name headline">Learning_O代码梳理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2024-03-17T16:00:00.000Z" title="发表于 2024-03-18 00:00:00">2024-03-18</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2024-07-24T10:05:14.196Z" title="更新于 2024-07-24 18:05:14">2024-07-24</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">4.5k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator"></span><span class="leancloud_visitors" id="/2024/03/18/NER/Learing_o/" data-flag-title="Learning_O代码梳理"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span class="leancloud-visitors-count" title="访问量"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为西安"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>西安</span><span class="post-meta-separator"></span><span class="post-meta-commentcount"><i class="anzhiyufont anzhiyu-icon-comments post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2024/03/18/NER/Learing_o/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2024/03/18/NER/Learing_o/" itemprop="commentCount"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="/img/tu/img(52).jpg"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2024/03/18/NER/Learing_o/"><header><a class="post-meta-categories" href="/categories/NER/" itemprop="url">NER</a><a href="/tags/NER/" tabindex="-1" itemprop="url">NER</a><h1 id="CrawlerTitle" itemprop="name headline">Learning_O代码梳理</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">奇冀</span><time itemprop="dateCreated datePublished" datetime="2024-03-17T16:00:00.000Z" title="发表于 2024-03-18 00:00:00">2024-03-18</time><time itemprop="dateCreated datePublished" datetime="2024-07-24T10:05:14.196Z" title="更新于 2024-07-24 18:05:14">2024-07-24</time></header><h1>主函数</h1>
<h2 id="创建解释器，添加命令行参数">创建解释器，添加命令行参数</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(...)</span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure>
<h2 id="设置随机数种子以及每个任务包含的的标签数量">设置随机数种子以及每个任务包含的的标签数量</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set_seed(args)</span><br><span class="line">per_types = args.per_types</span><br></pre></td></tr></table></figure>
<h2 id="持续学习">持续学习</h2>
<p>迭代每个任务</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> step_id <span class="keyword">in</span> <span class="built_in">range</span>(args.start_step, args.nb_tasks)</span><br></pre></td></tr></table></figure>
<p>获取当前任务的标签集，标签数量和 PAD ids。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">labels = get_labels_dy(args.labels, per_types, step_id=step_id)</span><br><span class="line">num_labels = <span class="built_in">len</span>(labels)</span><br><span class="line">pad_token_label_id = CrossEntropyLoss().ignore_index</span><br></pre></td></tr></table></figure>
<p>设置 model_name_or_path</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果是第一轮，则加载 bert-base-uncased 模型</span></span><br><span class="line"><span class="keyword">if</span> step_id == <span class="number">0</span>:</span><br><span class="line">    model_name_or_path = <span class="string">&quot;bert-base-uncased&quot;</span> </span><br><span class="line"><span class="keyword">else</span>: <span class="comment"># 否则加载上一轮模型</span></span><br><span class="line">    model_name_or_path = os.path.join(args.output_dir, <span class="string">&quot;task_&quot;</span> + <span class="built_in">str</span>(step_id - <span class="number">1</span>))      </span><br></pre></td></tr></table></figure>
<p>训练和评价模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_and_eval(args, labels, num_labels, pad_token_label_id, model_name_or_path,output_dir, data_dir, step_id)</span><br></pre></td></tr></table></figure>
<h1>准备数据集</h1>
<h2 id="read-examples-from-file">read_examples_from_file()</h2>
<h2 id="convert-examples-to-features">convert_examples_to_features()</h2>
<h2 id="load-and-cache-examples">load_and_cache_examples()</h2>
<h3 id="从文件中加载样本特征">从文件中加载样本特征</h3>
<p>如果 cached_features_file 存在，则直接从该文件中加载特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">features = torch.load(cached_features_file)</span><br></pre></td></tr></table></figure>
<p>否则先处理原始数据，再加载特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">examples = read_examples_from_file(data_dir, mode)</span><br><span class="line">features = convert_examples_to_features(...)</span><br></pre></td></tr></table></figure>
<h3 id="提取features的属性并构建数据集">提取features的属性并构建数据集</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">all_input_ids = torch.tensor([f.input_ids <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">all_input_mask = torch.tensor([f.input_mask <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">all_segment_ids = torch.tensor([f.segment_ids <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">all_label_ids = torch.tensor([f.label_ids <span class="keyword">for</span> f <span class="keyword">in</span> features], dtype=torch.long)</span><br><span class="line">dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)</span><br></pre></td></tr></table></figure>
<h3 id="返回该数据集">返回该数据集</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> dataset</span><br></pre></td></tr></table></figure>
<h1>工具函数</h1>
<h2 id="get-exemplar-means">get_exemplar_means()</h2>
<p><strong>计算每个类别的原型，即均值向量</strong></p>
<h3 id="1-将每个样本按标签分类">1. 将每个样本按标签分类</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建了一个字典，包含了所有可能的类别索引，每个类别对应一个空列表</span></span><br><span class="line">cls_exemplar = &#123;cls: [] <span class="keyword">for</span> cls <span class="keyword">in</span> <span class="built_in">range</span>(n_tags)&#125;  。</span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(support_reps, support_labels):</span><br><span class="line">    <span class="comment"># 将每个样本按照标签分类存储在cls_exemplar字典中</span></span><br><span class="line">    cls_exemplar[y.item()].append(x)</span><br></pre></td></tr></table></figure>
<h3 id="计算每个类别的原型">计算每个类别的原型</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> cls, exemplar <span class="keyword">in</span> cls_exemplar.items():</span><br><span class="line">    features = []</span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> exemplar:</span><br><span class="line">        feature.data = feature.data / feature.data.norm()  <span class="comment"># Normalize  </span></span><br><span class="line">        features.append(feature)</span><br><span class="line">        <span class="comment"># 如果当前类别下没有样本，则随机初始化一个与样本表示reps大小相同的张量作为该类别的原型</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(features) == <span class="number">0</span>:</span><br><span class="line">            mu_y = torch.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="built_in">tuple</span>(x.size())).to(args.device)</span><br><span class="line">            mu_y = mu_y.squeeze()  </span><br><span class="line">        <span class="comment"># 如果有，则计算当前类别的所有样本的reps的均值作为原型</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            features = torch.stack(features) </span><br><span class="line">            mu_y = features.mean(<span class="number">0</span>).squeeze()</span><br><span class="line">        mu_y.data = mu_y.data / mu_y.data.norm()  <span class="comment"># Normalize  </span></span><br><span class="line">        exemplar_means[cls] = mu_y</span><br></pre></td></tr></table></figure>
<h3 id="返回包含每个类别原型的列表">返回包含每个类别原型的列表</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> exemplar_means</span><br></pre></td></tr></table></figure>
<h2 id="get-support-encodings-and-labels-total">get_support_encodings_and_labels(_total)()</h2>
<p><strong>获取支持集的encodings和labels</strong></p>
<h3 id="获取train-loader，support-loader，support-o-loader中的encodings和labels">获取train_loader，support_loader，support_o_loader中的encodings和labels</h3>
<p>获取train_loader中每个批次的encodings和labels(仅get_support_encodings_and_labels_total)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_iterator = tqdm(train_loader, desc=<span class="string">&quot;Support data representations&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> index, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iterator):</span><br><span class="line">    encodings, labels = get_token_encodings_and_labels(args, model, batch)</span><br><span class="line">    encodings = encodings.view(-<span class="number">1</span>, encodings.shape[-<span class="number">1</span>])</span><br><span class="line">    labels = labels.flatten()</span><br><span class="line">    <span class="comment"># 过滤掉标签为填充标记的部分</span></span><br><span class="line">    idx = torch.where((labels - pad_token_label_id) != <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    support_encodings.append(encodings[idx])</span><br><span class="line">    support_labels.append(labels[idx])</span><br></pre></td></tr></table></figure>
<p>同样的操作获取support_loader和support_o_loader中每个批次的encodings和labels</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">support_iterator = tqdm(support_loader, desc=<span class="string">&quot;Support data representations&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> index, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(support_iterator):</span><br><span class="line">        ...</span><br><span class="line">support_o_iterator = tqdm(support_o_loader, desc=<span class="string">&quot;Support data representations&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> _, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(support_o_iterator):</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<h3 id="返回所有的encodings和labels">返回所有的encodings和labels</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> torch.cat(support_encodings), torch.cat(support_labels)</span><br></pre></td></tr></table></figure>
<h2 id="get-token-logits-and-labels">get_token_logits_and_labels</h2>
<p><strong>使用原有的预训练BERT-NER模型获取预测分数和输出标签</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    inputs = &#123;<span class="string">&quot;input_ids&quot;</span>: batch[<span class="number">0</span>], <span class="string">&quot;attention_mask&quot;</span>: batch[<span class="number">1</span>], </span><br><span class="line">                <span class="string">&quot;output_hidden_states&quot;</span>: <span class="literal">True</span>, <span class="string">&quot;mode&quot;</span>: <span class="string">&quot;dev&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">if</span> model.config.model_type != <span class="string">&quot;distilbert&quot;</span>:</span><br><span class="line">        inputs[<span class="string">&quot;token_type_ids&quot;</span>] = (batch[<span class="number">2</span>] <span class="keyword">if</span> model.config.model_type <span class="keyword">in</span> [<span class="string">&quot;bert&quot;</span>, <span class="string">&quot;xlnet&quot;</span>] </span><br><span class="line">                                    <span class="keyword">else</span> <span class="literal">None</span>)  <span class="comment"># XLM and RoBERTa don&quot;t use token_type_ids</span></span><br><span class="line">        outputs = model(**inputs)</span><br><span class="line">        logits = outputs[-<span class="number">1</span>] </span><br><span class="line"><span class="keyword">return</span> logits, label_batch</span><br></pre></td></tr></table></figure>
<h2 id="get-rehearsal-prototype">get_rehearsal_prototype()</h2>
<h3 id="加载支持集以及它们的encodings和labels">加载支持集以及它们的encodings和labels</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">support_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=<span class="string">&quot;memory&quot;</span>, data_dir=data_dir)</span><br><span class="line">support_o_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=<span class="string">&quot;memory_o&quot;</span>, data_dir=data_dir)</span><br><span class="line">support_sampler = SequentialSampler(support_dataset)</span><br><span class="line">support_dataloader = DataLoader(support_dataset, sampler=support_sampler, batch_size=args.eval_batch_size)</span><br><span class="line">support_o_dataloader = DataLoader(support_o_dataset, sampler=support_o_sampler, batch_size=args.eval_batch_size)</span><br><span class="line">support_encodings, support_labels = get_support_features_and_labels(args, model, support_dataloader, support_o_dataloader, pad_token_label_id)</span><br><span class="line"><span class="comment"># 将support_encodings归一化</span></span><br><span class="line">support_encodings = F.normalize(support_encodings)</span><br></pre></td></tr></table></figure>
<h3 id="计算类别相似度">计算类别相似度</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(labels)):  <span class="comment"># 迭代每个非&quot;O&quot;标签的类别</span></span><br><span class="line">    <span class="comment"># 计算类别i的样本之间的余弦相似度</span></span><br><span class="line">    support_reps_dists = torch.matmul(support_encodings[support_labels == i],</span><br><span class="line">                                          support_encodings[support_labels == i].T)</span><br><span class="line">    <span class="comment"># 将对角线上的元素（样本与自身的相似度）设置为0，以避免将自身视为原型。</span></span><br><span class="line">    support_reps_dists = torch.scatter(support_reps_dists, <span class="number">1</span>, torch.arange(support_reps_dists.shape[<span class="number">0</span>]).view(-<span class="number">1</span>, <span class="number">1</span>).to(args.device),<span class="number">0.</span>)</span><br><span class="line">    <span class="comment"># 计算类别i的类别相似度</span></span><br><span class="line">    prototype_dists.append(support_reps_dists[support_reps_dists &gt; <span class="number">0</span>].view(-<span class="number">1</span>).mean(-<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h3 id="返回类别相似度列表">返回类别相似度列表</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> prototype_dists</span><br></pre></td></tr></table></figure>
<h1>定义模型</h1>
<h2 id="MySftBertModel">MySftBertModel()</h2>
<h3 id="初始化-init">初始化 init</h3>
<p>接受Bert配置参数以及其他自定义参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">self.per_types = per_types  <span class="comment"># 设置每轮任务的类型数量。</span></span><br><span class="line">self.feat_dim = feat_dim  <span class="comment"># 设置特征维度。</span></span><br><span class="line">self.hidden_size = config.hidden_size  <span class="comment"># 设置隐藏状态的大小。</span></span><br><span class="line">self.num_labels = config.num_labels  <span class="comment"># 设置标签数量。</span></span><br><span class="line">self.bert = BertModel(config, add_pooling_layer=<span class="literal">False</span>) </span><br></pre></td></tr></table></figure>
<p>设置了分类器(classifier)和投影头(head)，根据mode选择性地设置分类器的输出层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">classifier_dropout = (  <span class="comment"># 设置分类器的dropout概率</span></span><br><span class="line">            config.classifier_dropout <span class="keyword">if</span> config.classifier_dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> config.hidden_dropout_prob</span><br><span class="line">        )</span><br><span class="line"><span class="keyword">if</span> mode == <span class="string">&quot;train&quot;</span>:  <span class="comment"># 根据不同模式设置线性分类器的不同输出维度</span></span><br><span class="line">    <span class="keyword">if</span> self.num_labels-<span class="number">1</span> &gt; self.per_types:  <span class="comment"># 对“O”样本重新标记过</span></span><br><span class="line">        self.classifier = nn.Linear(config.hidden_size, config.num_labels - self.per_types)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.classifier = nn.Linear(config.hidden_size, config.num_labels)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    self.classifier = nn.Linear(config.hidden_size, config.num_labels)</span><br></pre></td></tr></table></figure>
<p>设置不同的head（线性层或多层感知机）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> head == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">   self.head = nn.Linear(self.hidden_size, self.hidden_size)</span><br><span class="line"><span class="keyword">elif</span> head == <span class="string">&#x27;mlp&#x27;</span>:</span><br><span class="line">    self.head = nn.Sequential(</span><br><span class="line">        nn.Linear(self.hidden_size, self.hidden_size),</span><br><span class="line">        nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        nn.Linear(self.hidden_size, self.feat_dim)</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError(<span class="string">&#x27;head not supported: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(head))</span><br></pre></td></tr></table></figure>
<h3 id="前向传播-forward">前向传播 forward</h3>
<p><strong>提取特征</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用原有的Bert模型初步提取出样本的特征</span></span><br><span class="line">outputs = self.bert(...)</span><br><span class="line">features_enc = outputs[<span class="number">0</span>]   </span><br><span class="line"><span class="comment"># 通过self.head对进一步提取出样本的特征并归一化。</span></span><br><span class="line">features = F.normalize(self.head(features_enc.view(-<span class="number">1</span>, self.hidden_size)), dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 使用初步特征进行预测</span></span><br><span class="line">sequence_output = outputs[<span class="number">0</span>]</span><br><span class="line">sequence_output = self.dropout(sequence_output)</span><br><span class="line">logits = self.classifier(sequence_output)</span><br></pre></td></tr></table></figure>
<p>如果不是训练模式，直接返回features_enc，features，logits</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> mode != <span class="string">&quot;train&quot;</span>:</span><br><span class="line">    <span class="keyword">return</span> loss, features_enc, features, logits</span><br></pre></td></tr></table></figure>
<p><strong>计算损失函数</strong><br>
如果是第一轮训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.num_labels-<span class="number">1</span> == self.per_types:  </span><br><span class="line">    <span class="keyword">if</span> loss_name == <span class="string">&quot;supcon&quot;</span>:         loss = supcon_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_o&quot;</span>:     loss = supcon_o_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_o_ce&quot;</span>:  loss = supcon_o_loss+ce_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_o_bce&quot;</span>: loss = supcon_o_loss + bce_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;ce&quot;</span>:           loss = ce_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;bce_o&quot;</span>:        loss = bce_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_ce&quot;</span>:    loss = supcon_loss + ce_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_bce&quot;</span>:   loss = supcon_loss + bce_loss</span><br></pre></td></tr></table></figure>
<p>如果不是第一轮训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> self.num_labels &gt; self.per_types: </span><br><span class="line">    <span class="comment"># 整理新类别标签labels_new，新类别样本的logits：student_new 以及</span></span><br><span class="line">    <span class="comment"># 旧类别样本的logits：s_logits，teacher模型的logits：old_logits</span></span><br><span class="line">    labels_new, student_new, s_logits, old_logits = gather_rh_ce( labels, t_logits, </span><br><span class="line">                                            logits, self.num_labels - self.per_types)</span><br><span class="line">    <span class="keyword">if</span> loss_name == <span class="string">&quot;supcon&quot;</span>:        loss = supcon_loss+kd_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_nokd&quot;</span>: loss = supcon_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_o&quot;</span>:    loss = supcon_o_loss+kd_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_o_ce&quot;</span>: loss = supcon_o_loss+ce_loss+kd_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_o_bce&quot;</span>:loss = supcon_o_loss + bce_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;ce&quot;</span>:          loss = ce_loss+kd_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;bce_o&quot;</span>:       loss = bce_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_ce&quot;</span>:   loss = supcon_loss+ce_loss+kd_loss</span><br><span class="line">    <span class="keyword">elif</span> loss_name == <span class="string">&quot;supcon_bce&quot;</span>:  loss = supcon_loss+bce_loss</span><br></pre></td></tr></table></figure>
<h3 id="3-返回-loss-features-enc-features-logits">3. 返回 loss, features_enc, features, logits</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> loss, features_enc, features, logits</span><br></pre></td></tr></table></figure>
<h1>训练和评估模型</h1>
<h2 id="train-and-eval">train_and_eval( )</h2>
<h3 id="加载上一轮预训练的参数配置、模型和分词器">加载上一轮预训练的参数配置、模型和分词器</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建模型配置、模型类别和分词器类</span></span><br><span class="line">config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]</span><br><span class="line"><span class="comment"># 如果是第一轮，则直接加载 bert-base-uncased 模型</span></span><br><span class="line">config = config_class.from_pretrained(args.config_name <span class="keyword">if</span> args.config_name <span class="keyword">else</span> model_name_or_path，num_labels=num_labels)</span><br><span class="line">tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name <span class="keyword">if</span> args.tokenizer_name <span class="keyword">else</span> model_name_or_path,do_lower_case=args.do_lower_case)</span><br><span class="line">model = model_class.from_pretrained(model_name_or_path, from_tf=<span class="built_in">bool</span>(<span class="string">&quot;.ckpt&quot;</span> <span class="keyword">in</span> model_name_or_path),config=config)</span><br></pre></td></tr></table></figure>
<h3 id="获取训练集">获取训练集</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_dataset=TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)</span></span><br><span class="line">train_dataset=load_and_cache_examples(args,tokenizer,labels,pad_token_label_id,mode=<span class="string">&quot;rehearsal&quot;</span>,data_dir=data_dir)</span><br><span class="line"><span class="comment"># 顺序采样</span></span><br><span class="line">train_sampler = SequentialSampler(train_dataset) <span class="keyword">if</span> args.local_rank == -<span class="number">1</span> <span class="keyword">else</span> DistributedSampler(train_dataset)</span><br><span class="line"><span class="comment"># 创建训练数据加载器</span></span><br><span class="line">train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)  </span><br></pre></td></tr></table></figure>
<h3 id="获取旧模型的特征">获取旧模型的特征</h3>
<p><strong>teacher_evaluate()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果当前不是第一个任务，则需要对老师模型进行评估。</span></span><br><span class="line"><span class="keyword">if</span> step_id &gt; <span class="number">0</span>: </span><br><span class="line">    t_logits, out_new_labels = teacher_evaluate(args, train_dataloader, model, tokenizer,labels,</span><br><span class="line">                                                pad_token_label_id, mode=<span class="string">&quot;train&quot;</span>, data_dir=data_dir)</span><br><span class="line">    model.new_classifier()  <span class="comment"># 创建一个新的分类器</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    t_logits = <span class="literal">None</span></span><br><span class="line">    out_new_labels = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<h3 id="训练模型">训练模型</h3>
<p><strong>train()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">global_step, tr_loss = train(args, train_dataset, train_dataloader, model, tokenizer, labels,</span><br><span class="line">                                pad_token_label_id, data_dir=data_dir, output_dir=output_dir,</span><br><span class="line">                                t_logits=t_logits, out_new_labels=out_new_labels)</span><br><span class="line"><span class="comment"># 保存训练过程中得到的模型参数、配置和分词器    </span></span><br><span class="line">model_to_save.save_pretrained(output_dir)</span><br><span class="line">tokenizer.save_pretrained(output_dir)</span><br><span class="line">torch.save(args, os.path.join(output_dir, <span class="string">&quot;training_args.bin&quot;</span>))                            </span><br></pre></td></tr></table></figure>
<h3 id="在开发集上评估模型">在开发集上评估模型</h3>
<p><strong>evaluate()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于每个检查点，加载模型并进行评估</span></span><br><span class="line"><span class="keyword">for</span> checkpoint <span class="keyword">in</span> checkpoints:</span><br><span class="line">    model = model_class.from_pretrained(checkpoint, mode=<span class="string">&quot;dev&quot;</span>)</span><br><span class="line">    train_dataloader=<span class="literal">None</span></span><br><span class="line">     _, result,  _ = evaluate(args, model, tokenizer, labels, pad_token_label_id, mode=<span class="string">&quot;dev&quot;</span>,</span><br><span class="line">                            data_dir=data_dir, prefix=global_step)</span><br></pre></td></tr></table></figure>
<h3 id="在测试集上进行预测">在测试集上进行预测</h3>
<p><strong>evaluate()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型和分词器</span></span><br><span class="line">tokenizer = tokenizer_class.from_pretrained(output_dir, do_lower_case=args.do_lower_case)</span><br><span class="line">model = model_class.from_pretrained(output_dir, mode=<span class="string">&quot;test&quot;</span>)</span><br><span class="line"><span class="comment"># 调用 evaluate 函数对测试集进行预测，获取macro-F1和micro-F1结果以及预测的标签。</span></span><br><span class="line">macro_results, micro_results, predictions = evaluate(args, model, tokenizer, labels,</span><br><span class="line">                                                    pad_token_label_id, mode=<span class="string">&quot;test&quot;</span>, data_dir=data_dir)</span><br></pre></td></tr></table></figure>
<h2 id="teacher-evaluate">teacher_evaluate()</h2>
<h3 id="根据不同模式设置数据集加载器">根据不同模式设置数据集加载器</h3>
<p>如果模式是 “train”，，则使用训练数集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">    eval_dataloader = train_dataloader</span><br></pre></td></tr></table></figure>
<p>如果模式是 “dev”，则使用开发集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> mode == <span class="string">&quot;dev&quot;</span>:</span><br><span class="line">    eval_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=mode,data_dir=data_dir)</span><br><span class="line">    eval_sampler = SequentialSampler(eval_dataset) <span class="keyword">if</span> args.local_rank == -<span class="number">1</span> <span class="keyword">else</span> DistributedSampler(eval_dataset)</span><br><span class="line">    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)</span><br></pre></td></tr></table></figure>
<h3 id="评估模型">评估模型</h3>
<p>将模型设置为评估模式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
<p>使用 get_token_logits_and_labels 函数获取每个batch的预测分数 logits 和输出标签 out_labels</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(eval_dataloader, desc=<span class="string">&quot;Evaluating&quot;</span>):</span><br><span class="line">    logits, out_labels = get_token_logits_and_labels(args, model, batch)</span><br><span class="line">    <span class="comment"># 对评估步骤计数，以便跟踪已评估的批次数量</span></span><br><span class="line">    nb_eval_steps += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 将每个批次的 logits 分数添加到 logits_list 列表中</span></span><br><span class="line">    logits_list.append(logits.detach().cpu())</span><br></pre></td></tr></table></figure>
<h3 id="用原型重新标记阈值重新标记旧实体类">用原型重新标记阈值重新标记旧实体类</h3>
<p>计算原型重新标记阈值和与每个样本的原型相似度最高的实体类别<br>
<strong>evaluate()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算每个批次样本中原型相似度最大值所在的类别索引 preds</span></span><br><span class="line"><span class="comment"># 每个批次样本与每个类别的原型相似度的最大值 emissions</span></span><br><span class="line"><span class="comment"># 根据原有模型预测的标签索引序列 out_label_ids</span></span><br><span class="line"><span class="comment"># 每个旧类别的原型重新标记阈值列表（还未乘βi）prototype_dists</span></span><br><span class="line">preds, emissions, out_label_ids, prototype_dists = evaluate(args, model, tokenizer, labels, pad_token_label_id, </span><br><span class="line">                                                        mode=<span class="string">&quot;rehearsal&quot;</span>, data_dir=data_dir)</span><br><span class="line"><span class="comment"># 计算原型重新标记阈值 (根据不同的任务步骤i来调整超参数βi)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(current_task_id):</span><br><span class="line">    <span class="keyword">if</span> args.change_th:</span><br><span class="line">        task_para = th_para - (current_task_id - i - <span class="number">1</span>)*th_reduction  <span class="comment"># βi</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        task_para = th_para</span><br><span class="line">        prototype_dists[i*args.per_types+<span class="number">1</span>:(i+<span class="number">1</span>)*args.per_types+<span class="number">1</span>] *= task_para</span><br></pre></td></tr></table></figure>
<p>重新标记旧实体类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(out_label_ids.shape[<span class="number">0</span>]):  <span class="comment"># 迭代每个batch  </span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(out_label_ids.shape[<span class="number">1</span>]):  <span class="comment"># 迭代每个样本  </span></span><br><span class="line">        idx = preds[i][j]   <span class="comment"># 根据原型相似度预测的类别索引</span></span><br><span class="line">        <span class="comment"># 如果原型的相似度大于重新标记阈值并且预测的标签是旧实体类的标签</span></span><br><span class="line">        <span class="keyword">if</span> emissions[i][j] &gt; prototype_dists[idx].item() <span class="keyword">and</span> out_label_ids[i][j] &lt; <span class="built_in">len</span>(labels) - args.per_types: </span><br><span class="line">                out_label_new_list[i].append(preds[i][j])  <span class="comment"># 则将该“O”预测为这个旧实体类  </span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 否则，保持原始的标签不变</span></span><br><span class="line">            out_label_new_list[i].append(out_label_ids[i][j])</span><br></pre></td></tr></table></figure>
<h3 id="返回-logits-list-out-label-new-list">返回 logits_list, out_label_new_list</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> logits_list, out_label_new_list</span><br></pre></td></tr></table></figure>
<h2 id="evaluate">evaluate ()</h2>
<h3 id="读取数据集">读取数据集</h3>
<p>读取eval_dataset，support_dataset，support_o_dataset，train_dataset。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">eval_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=mode, data_dir=data_dir)</span><br><span class="line">support_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=<span class="string">&quot;memory&quot;</span>, data_dir=data_dir)</span><br><span class="line">support_o_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=<span class="string">&quot;memory_o&quot;</span>, data_dir=data_dir)</span><br><span class="line">train_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=<span class="string">&quot;train&quot;</span>, data_dir=data_dir)</span><br><span class="line"><span class="comment"># 顺序采样</span></span><br><span class="line">eval_sampler = SequentialSampler(eval_dataset) <span class="keyword">if</span> args.local_rank == -<span class="number">1</span> <span class="keyword">else</span> DistributedSampler(eval_dataset)</span><br><span class="line">eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)</span><br><span class="line">support_sampler = SequentialSampler(support_dataset) <span class="keyword">if</span> args.local_rank == -<span class="number">1</span> <span class="keyword">else</span> DistributedSampler(support_dataset)</span><br><span class="line">support_o_sampler = SequentialSampler(support_o_dataset) <span class="keyword">if</span> args.local_rank == -<span class="number">1</span> <span class="keyword">else</span> DistributedSampler(support_o_dataset)</span><br><span class="line">train_sampler = SequentialSampler(train_dataset) <span class="keyword">if</span> args.local_rank == -<span class="number">1</span> <span class="keyword">else</span> DistributedSampler(train_dataset)</span><br><span class="line"><span class="comment"># 数据集加载器</span></span><br><span class="line">support_dataloader = DataLoader(support_dataset, sampler=support_sampler, batch_size=args.eval_batch_size)</span><br><span class="line">support_o_dataloader = DataLoader(support_o_dataset, sampler=support_o_sampler, batch_size=args.eval_batch_size)</span><br><span class="line">train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.eval_batch_size)</span><br></pre></td></tr></table></figure>
<h3 id="获取支持数据集的embbedings和labels">获取支持数据集的embbedings和labels</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">support_encodings, support_labels = get_support_encodings_and_labels_total(args, model, support_dataloader, support_o_dataloader, train_dataloader, pad_token_label_id)</span><br></pre></td></tr></table></figure>
<h3 id="三种重新标记来自旧类别的“O”的策略">三种重新标记来自旧类别的“O”的策略</h3>
<h4 id="使用原型重新标记">使用原型重新标记</h4>
<p>基于“O”样本与原型之间的距离<br>
<strong>计算每个类别的原型</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exemplar_means = get_exemplar_means(args, support_encodings, support_labels)</span><br></pre></td></tr></table></figure>
<p><strong>计算原型重新标记阈值以及“O”与原型的最高相似度</strong></p>
<p>利用 NNClassification() 计算nn_preds，nn_emissions，prototype_dists</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(eval_iterator):</span><br><span class="line">    batch = <span class="built_in">tuple</span>(t.to(args.device) <span class="keyword">for</span> t <span class="keyword">in</span> batch)</span><br><span class="line">    <span class="comment"># 循环迭代 eval_iterator，使用原有的模型获取每个批次的encodings和labels</span></span><br><span class="line">    encodings, encoding_labels = get_token_encodings_and_labels(args, model, batch)</span><br><span class="line">    <span class="comment"># 如果是rehearsal模式，则去除掉当前task样本的support_encodings和support_labels再进行预测。</span></span><br><span class="line">    <span class="keyword">if</span> mode==<span class="string">&quot;rehearsal&quot;</span>:</span><br><span class="line">        cls = NNClassification()</span><br><span class="line">        support_encodings = support_encodings[support_labels &lt; <span class="built_in">len</span>(labels) - args.per_types]</span><br><span class="line">        support_labels = support_labels[support_labels &lt; <span class="built_in">len</span>(labels) - args.per_types]</span><br><span class="line">        nn_preds(batch_size, sent_len) 包含每个样本中原型相似度最大值所在的类别索引</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        nn_preds(batch_size, sent_len) 包含每个样本中原型相似度最大值所在的类别索引</span></span><br><span class="line"><span class="string">        nn_emissions(batch_size, sent_len, ndim) 包含每个样本与每个类别的原型相似度的最大值</span></span><br><span class="line"><span class="string">        prototype_dists 每个旧类别的原型重新标记阈值列表（还未乘βi）</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        nn_preds, nn_emissions, prototype_dists = cls.nn_classifier_dot_prototype(encodings, support_encodings, support_labels, exemplar_means)</span><br></pre></td></tr></table></figure>
<h4 id="使用最近邻重新标记">使用最近邻重新标记</h4>
<p>基于“O”样本与每个类别示例之间的距离</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.cls_name == <span class="string">&quot;ncm_dot&quot;</span>:  </span><br><span class="line">    cls = NcmClassification()</span><br><span class="line">    nn_preds = cls.ncm_classifier_dot(encodings, support_encodings, support_labels, exemplar_means)</span><br></pre></td></tr></table></figure>
<h4 id="使用原有模型重新标记">使用原有模型重新标记</h4>
<p>作为前两种方法的参考标注</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> args.cls_name == <span class="string">&quot;linear&quot;</span>:</span><br><span class="line">    nn_preds, encoding_labels = get_token_logits_and_labels(args, model, batch)</span><br></pre></td></tr></table></figure>
<h3 id="保存预测结果">保存预测结果</h3>
<p>将每个批次的预测结果追加到 preds 中，并将作为参考标准的预测标签保存到 out_label_ids 中。如果当前模式是rehearsal模式，还会保存emissions。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> preds <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># 第一次预测</span></span><br><span class="line">    preds = nn_preds.detach().cpu().numpy()</span><br><span class="line">    out_label_ids = encoding_labels.detach().cpu().numpy()</span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&quot;rehearsal&quot;</span>:</span><br><span class="line">        emissions = nn_emissions.detach().cpu().numpy()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    preds = np.append(preds, nn_preds.detach().cpu().numpy(), axis=<span class="number">0</span>)</span><br><span class="line">    out_label_ids = np.append(out_label_ids, encoding_labels.detach().cpu().numpy(), axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&quot;rehearsal&quot;</span>:</span><br><span class="line">        emissions = np.append(emissions, nn_emissions.detach().cpu().numpy(), axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="预测结果">预测结果</h3>
<p>如果当前模式是rehearsal模式，那么函数直接将返回 preds、 emissions、out_label_ids 和prototype_dists。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> mode == <span class="string">&quot;rehearsal&quot;</span>:</span><br><span class="line">    <span class="keyword">return</span> preds, emissions, out_label_ids, prototype_dists</span><br></pre></td></tr></table></figure>
<p>如果使用的是线性分类器，根据 preds 得出预测的最大logits？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.cls_name == <span class="string">&quot;linear&quot;</span>:</span><br><span class="line">    preds = np.argmax(preds, axis=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>out_label_list 和 preds_list存储使用原有模型和使用自定义方法预测的标签字符串序列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 label_map 字典，将标签的索引映射到相应标签的字符串名称。</span></span><br><span class="line">label_map = &#123;i: <span class="string">&quot;I-&quot;</span>+label <span class="keyword">for</span> i, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(labels)&#125;</span><br><span class="line">label_map[<span class="number">0</span>] = <span class="string">&quot;O&quot;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(out_label_ids.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(out_label_ids.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> out_label_ids[i, j] != pad_token_label_id:</span><br><span class="line">            out_label_list[i].append(label_map[out_label_ids[i][j]])</span><br><span class="line">            preds_list[i].append(label_map[preds[i][j]])</span><br></pre></td></tr></table></figure>
<p>输出评价指标结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 seqeval 库计算 F1-score。</span></span><br><span class="line">metric = load_metric(<span class="string">&quot;seqeval&quot;</span>)</span><br><span class="line">metric.add_batch(predictions=preds_list, references=out_label_list)</span><br><span class="line">macro_results, micro_results, _ = compute_metrics(metric)</span><br></pre></td></tr></table></figure>
<p>返回评价指标结果以及预测的标签序列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> macro_results, micro_results, preds_list</span><br></pre></td></tr></table></figure>
<h2 id="train">train()</h2>
<h3 id="计算训练总步数t-total和训练轮数num-train-epochs">计算训练总步数t_total和训练轮数num_train_epochs</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果设置了训练最大步数max_steps，则t_total = args.max_steps，并计算num_train_epochs，否则根据num_train_epochs计算t_total。</span></span><br><span class="line"><span class="keyword">if</span> args.max_steps &gt; <span class="number">0</span>:</span><br><span class="line">    t_total = args.max_steps</span><br><span class="line">    args.num_train_epochs = args.max_steps // (<span class="built_in">len</span>(train_dataloader) // args.gradient_accumulation_steps) + <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    t_total = <span class="built_in">len</span>(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs</span><br></pre></td></tr></table></figure>
<h3 id="配置优化器">配置优化器</h3>
<p>使用AdamW优化器，使用了。权重衰减和学习率调节器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">no_decay = [<span class="string">&quot;bias&quot;</span>, <span class="string">&quot;LayerNorm.weight&quot;</span>]  <span class="comment"># 不需要衰减的参数</span></span><br><span class="line">optimizer_grouped_parameters = [</span><br><span class="line">    &#123;<span class="string">&quot;params&quot;</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">    <span class="string">&quot;weight_decay&quot;</span>: args.weight_decay&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;params&quot;</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">&quot;weight_decay&quot;</span>: <span class="number">0.0</span>&#125;</span><br><span class="line">]</span><br><span class="line">optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)</span><br><span class="line">scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)</span><br></pre></td></tr></table></figure>
<h3 id="训练">训练</h3>
<p>迭代每一轮</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> train_iterator:</span><br><span class="line">    <span class="keyword">if</span> epoch &gt;= args.start_train_o_epoch:</span><br></pre></td></tr></table></figure>
<p>获取每个类别的类别相似度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">prototype_dists = get_rehearsal_prototype(args, model, tokenizer, labels,</span><br><span class="line">                                   pad_token_label_id, mode=<span class="string">&quot;rehearsal&quot;</span>,</span><br><span class="line">                                   data_dir=data_dir)</span><br></pre></td></tr></table></figure>
<p>获取样本的logits和标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按批次遍历训练集中的数据</span></span><br><span class="line"><span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(epoch_iterator):</span><br><span class="line">    model.train()  <span class="comment"># 将模型切换到训练模式</span></span><br><span class="line">    <span class="keyword">if</span> num_labels-<span class="number">1</span> &gt; args.per_types:  <span class="comment"># 如果不是第一轮训练</span></span><br><span class="line">        t_logits_step = t_logits[step]</span><br><span class="line">        new_labels = out_new_labels[step * args.train_batch_size:step * args.train_batch_size + <span class="built_in">len</span>(batch[<span class="number">3</span>])]</span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># 如果是第一轮训练，使用训练集的原始标签</span></span><br><span class="line">        t_logits_step = <span class="literal">None</span></span><br><span class="line">        new_labels = batch[<span class="number">3</span>]</span><br><span class="line">    <span class="keyword">if</span> epoch &gt;= args.start_train_o_epoch:</span><br><span class="line">        loss_name = args.loss_name2  <span class="comment"># 实体和“O”的联合损失函数</span></span><br><span class="line">        cls = NNClassification()</span><br><span class="line">        encodings, encoding_labels = get_token_features_and_labels(args, model, batch)</span><br></pre></td></tr></table></figure>
<p>计算样本之间的余弦相似度分数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    # top_emissions_step(batch_size*set_len, batch_size*set_len):存储样本之间大于实体阈值的余弦相似度分数</span><br><span class="line">    # 选择类别相似度的中位数作为实体阈值 th_dists</span><br><span class="line">    top_emissions_step, _ = cls.get_top_emissions_with_th(encodings, encoding_labels, </span><br><span class="line">                                                        th_dists=torch.median(prototype_dists).item())</span><br><span class="line">else:</span><br><span class="line">    top_emissions_step = top_emissions</span><br></pre></td></tr></table></figure>
<p>用自定义的模型进行训练，获取损失值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">inputs = &#123;<span class="string">&quot;input_ids&quot;</span>: batch[<span class="number">0</span>],  </span><br><span class="line">        <span class="string">&quot;attention_mask&quot;</span>: batch[<span class="number">1</span>],  </span><br><span class="line">        <span class="string">&quot;token_type_ids&quot;</span>: batch[<span class="number">2</span>] <span class="keyword">if</span> args.model_type <span class="keyword">in</span> [<span class="string">&quot;bert&quot;</span>, <span class="string">&quot;xlnet&quot;</span>] <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">        <span class="comment"># XLM and RoBERTa don&quot;t use segment_ids</span></span><br><span class="line">        <span class="string">&quot;labels&quot;</span>: new_labels,  </span><br><span class="line">        <span class="string">&quot;t_logits&quot;</span>: t_logits_step,  </span><br><span class="line">        <span class="string">&quot;mode&quot;</span>: <span class="string">&quot;train&quot;</span>,  </span><br><span class="line">        <span class="string">&quot;loss_name&quot;</span>: loss_name,  </span><br><span class="line">        <span class="string">&quot;top_emissions&quot;</span>: top_emissions_step,</span><br><span class="line">        <span class="string">&quot;topk_th&quot;</span>: <span class="literal">True</span>  </span><br><span class="line">        &#125;</span><br><span class="line">outputs = model(**inputs)  </span><br><span class="line">loss = outputs[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 如果设置了梯度累积步数，则需要对损失值进行除以梯度累积步数，以得到平均损失值</span></span><br><span class="line"><span class="keyword">if</span> args.gradient_accumulation_steps &gt; <span class="number">1</span>:</span><br><span class="line">    loss = loss / args.gradient_accumulation_steps</span><br></pre></td></tr></table></figure>
<p>更新参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">loss.backward()  <span class="comment"># 后向传播</span></span><br><span class="line">tr_loss += loss.item()</span><br><span class="line"><span class="comment"># 如果达到梯度累计步数</span></span><br><span class="line"><span class="keyword">if</span> (step + <span class="number">1</span>) % args.gradient_accumulation_steps == <span class="number">0</span>:</span><br><span class="line">    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm) </span><br><span class="line">    optimizer.step()  </span><br><span class="line">    scheduler.step()  </span><br><span class="line">    optimizer.zero_grad()  <span class="comment"># 清除优化器中所有参数的梯度</span></span><br><span class="line">    global_step += <span class="number">1</span>  <span class="comment"># 更新全局步数</span></span><br></pre></td></tr></table></figure>
<h3 id="评估">评估</h3>
<p>在开发集上评估模型性能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">_, results, _ = evaluate(args, model, tokenizer, labels, pad_token_label_id, mode=<span class="string">&quot;dev&quot;</span>,</span><br><span class="line">                                     data_dir=data_dir)</span><br></pre></td></tr></table></figure>
<p>保存模型及参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_to_save.save_pretrained(output_dir)</span><br><span class="line">torch.save(args, os.path.join(output_dir, <span class="string">&quot;training_args.bin&quot;</span>)) </span><br></pre></td></tr></table></figure>
<p>达到最大步数时停止训练</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if args.max_steps &gt; 0 and global_step &gt; args.max_steps:  </span><br><span class="line">    epoch_iterator.close()  # 关闭当前的 epoch 迭代器</span><br><span class="line">    break</span><br></pre></td></tr></table></figure>
<h3 id="返回全局步数和平均损失">返回全局步数和平均损失</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> global_step, tr_loss / global_step  </span><br></pre></td></tr></table></figure>
<h1>分类器</h1>
<h2 id="NNClassification">NNClassification()</h2>
<h3 id="nn-classifier-dot-prototype">nn_classifier_dot_prototype()</h3>
<p><strong>根据原型进行重新标记来自旧实体类别的“O”</strong><br>
计算“O”与每个类别原型的最大相似度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将输入的表示 reps 重塑为二维张量，并对其进行归一化处理。</span></span><br><span class="line">feature = reps.view(-<span class="number">1</span>, reps.shape[-<span class="number">1</span>])  <span class="comment"># (batch_size, ndim)</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(feature.size(<span class="number">0</span>)):  <span class="comment"># Normalize</span></span><br><span class="line">    feature.data[j] = feature.data[j] / feature.data[j].norm()</span><br><span class="line">    means = torch.stack([exemplar_means[cls] <span class="keyword">for</span> cls <span class="keyword">in</span> <span class="built_in">range</span>(n_tags)])  <span class="comment"># (n_classes, ndim)</span></span><br><span class="line">    dists = torch.matmul(feature, means.T)  <span class="comment"># (batch_size, n_classes)</span></span><br><span class="line">    dists[:, <span class="number">0</span>] = torch.zeros(<span class="number">1</span>).to(reps.device)  <span class="comment"># 将第一列真正的“O” 类别的相似度设为0</span></span><br><span class="line">    <span class="comment"># emissions 包含每个样本中原型相似度的最大值，tags 包含每个样本中原型相似度最大值所在的类别索引。</span></span><br><span class="line">    emissions, tags = dists.<span class="built_in">max</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>计算每个类别的原型重新标记阈值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将support_reps 重塑为二维张量，并对其进行归一化处理。</span></span><br><span class="line">support_reps = support_reps.view(-<span class="number">1</span>, support_reps.shape[-<span class="number">1</span>])</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(support_reps.size(<span class="number">0</span>)):  <span class="comment"># Normalize</span></span><br><span class="line">    support_reps.data[j] = support_reps.data[j] / support_reps.data[j].norm()</span><br><span class="line">support_reps = F.normalize(support_reps)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_tags):</span><br><span class="line">    <span class="comment"># 计算每个类别原型与支持集中对应类别的样本的相似度</span></span><br><span class="line">    support_reps_dists = torch.matmul(support_reps[support_tags==i], means[i].T)</span><br><span class="line">    <span class="comment"># 沿着最后一个维度（即特征维度）寻找最小值，并返回这些最小值以及对应的索引</span></span><br><span class="line">    prototype_dists.append(support_reps_dists.<span class="built_in">min</span>(-<span class="number">1</span>)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h3 id="get-top-emissions-with-th">get_top_emissions_with_th()</h3>
<p>计算样本之间的余弦相似度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scores = self._euclidean_metric_dot_2(reps.view(-<span class="number">1</span>, ndim), reps.view(-<span class="number">1</span>, ndim), <span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 排除“O”样本的分数（第二维）</span></span><br><span class="line">        scores = torch.where(reps_labels == <span class="number">0</span>, scores.double(), -<span class="number">100.</span>)  </span><br><span class="line">        <span class="comment"># 排除样本与自身的分数</span></span><br><span class="line">        scores = torch.scatter(scores, <span class="number">1</span>,</span><br><span class="line">                               torch.arange(scores.shape[<span class="number">0</span>]).view(-<span class="number">1</span>, <span class="number">1</span>).to(device), -<span class="number">100.</span>)</span><br></pre></td></tr></table></figure>
<p>筛选出大于实体阈值的分数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top_emissions = scores &gt; th_dists</span><br></pre></td></tr></table></figure>
<p>返回 top_emissions, scores</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> top_emissions, scores</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">奇冀</div><div class="post-copyright__author_desc">Hi~同行者</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://example.com/2024/03/18/NER/Learing_o/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2024/03/18/NER/Learing_o/')">Learning_O代码梳理</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2024/03/18/NER/Learing_o/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Learning_O代码梳理&amp;url=http://example.com/2024/03/18/NER/Learing_o/&amp;pic=/img/tu/img(52).jpg" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">奇冀の观猹录</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__category-list"><a class="post-meta__box__categoryes" href="/categories/NER/"><span class="categoryes-punctuation"> <i class="anzhiyufont anzhiyu-icon-inbox"></i></span>NER<span class="categoryesPageCount">17</span></a></div><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/NER/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>NER<span class="tagsPageCount">16</span></a></div></div><div class="post_share"><div class="social-share" data-image="/img/tu/img(47).jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/03/18/NER/O%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(97).jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Learning_O说明文档</div></div></a></div><div class="next-post pull-right"><a href="/2024/04/24/NER/Few-shot%E4%BB%A3%E7%A0%81%E6%A2%B3%E7%90%86/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(10).jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Few-shot代码梳理（粗略版）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2024/02/15/NER/RNN%E6%A8%A1%E5%9E%8B/" title="RNN模型"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(18).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-02-15</div><div class="title">RNN模型</div></div></a></div><div><a href="/2024/02/15/NER/BERT&Transformer/" title="BERT &amp; Transformer &amp; CRF"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(10).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-02-15</div><div class="title">BERT &amp; Transformer &amp; CRF</div></div></a></div><div><a href="/2024/04/24/NER/Few-Shot%E4%BB%A3%E7%A0%81/" title="Few-Shot代码"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(15).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-04-24</div><div class="title">Few-Shot代码</div></div></a></div><div><a href="/2024/04/24/NER/Few-shot%E4%BB%A3%E7%A0%81%E6%A2%B3%E7%90%86/" title="Few-shot代码梳理（粗略版）"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(10).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-04-24</div><div class="title">Few-shot代码梳理（粗略版）</div></div></a></div><div><a href="/2024/02/07/NER/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/" title="文本预处理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(20).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-02-07</div><div class="title">文本预处理</div></div></a></div><div><a href="/2024/02/07/NER/Pre-training-language-model-main/%E7%AC%AC%E4%B8%80%E7%AF%87%20Transformer%E3%80%81GPT%E3%80%81BERT%EF%BC%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%EF%BC%88%E7%90%86%E8%AE%BA%EF%BC%89/04%20%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88n%E5%85%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%89/" title="统计语言模型（n元语言模型）"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(5).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-02-07</div><div class="title">统计语言模型（n元语言模型）</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-switch"><span class="first-comment">Valine</span><span id="switch-btn"></span><span class="second-comment">Twikoo</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="twikoo-wrap"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description"><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">这有关于<b style="color:#fff">产品、设计、开发</b>相关的问题和看法，还有<b style="color:#fff">文章翻译</b>和<b style="color:#fff">分享</b>。</div><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">相信你可以在这里找到对你有用的<b style="color:#fff">知识</b>和<b style="color:#fff">教程</b>。</div></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">奇冀</h1><div class="author-info__desc">Hi~同行者</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/Alive0103/Alive0103.github.io" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/1509553238?spm_id_from=333.1007.0.0" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来看我的博客鸭~希望对你有所帮助</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">主函数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%A7%A3%E9%87%8A%E5%99%A8%EF%BC%8C%E6%B7%BB%E5%8A%A0%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0"><span class="toc-number">1.1.</span> <span class="toc-text">创建解释器，添加命令行参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%A7%8D%E5%AD%90%E4%BB%A5%E5%8F%8A%E6%AF%8F%E4%B8%AA%E4%BB%BB%E5%8A%A1%E5%8C%85%E5%90%AB%E7%9A%84%E7%9A%84%E6%A0%87%E7%AD%BE%E6%95%B0%E9%87%8F"><span class="toc-number">1.2.</span> <span class="toc-text">设置随机数种子以及每个任务包含的的标签数量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.3.</span> <span class="toc-text">持续学习</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">准备数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#read-examples-from-file"><span class="toc-number">2.1.</span> <span class="toc-text">read_examples_from_file()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#convert-examples-to-features"><span class="toc-number">2.2.</span> <span class="toc-text">convert_examples_to_features()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#load-and-cache-examples"><span class="toc-number">2.3.</span> <span class="toc-text">load_and_cache_examples()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E6%96%87%E4%BB%B6%E4%B8%AD%E5%8A%A0%E8%BD%BD%E6%A0%B7%E6%9C%AC%E7%89%B9%E5%BE%81"><span class="toc-number">2.3.1.</span> <span class="toc-text">从文件中加载样本特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E5%8F%96features%E7%9A%84%E5%B1%9E%E6%80%A7%E5%B9%B6%E6%9E%84%E5%BB%BA%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.3.2.</span> <span class="toc-text">提取features的属性并构建数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E8%AF%A5%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.3.3.</span> <span class="toc-text">返回该数据集</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">工具函数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#get-exemplar-means"><span class="toc-number">3.1.</span> <span class="toc-text">get_exemplar_means()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%B0%86%E6%AF%8F%E4%B8%AA%E6%A0%B7%E6%9C%AC%E6%8C%89%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB"><span class="toc-number">3.1.1.</span> <span class="toc-text">1. 将每个样本按标签分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%AF%8F%E4%B8%AA%E7%B1%BB%E5%88%AB%E7%9A%84%E5%8E%9F%E5%9E%8B"><span class="toc-number">3.1.2.</span> <span class="toc-text">计算每个类别的原型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E5%8C%85%E5%90%AB%E6%AF%8F%E4%B8%AA%E7%B1%BB%E5%88%AB%E5%8E%9F%E5%9E%8B%E7%9A%84%E5%88%97%E8%A1%A8"><span class="toc-number">3.1.3.</span> <span class="toc-text">返回包含每个类别原型的列表</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#get-support-encodings-and-labels-total"><span class="toc-number">3.2.</span> <span class="toc-text">get_support_encodings_and_labels(_total)()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96train-loader%EF%BC%8Csupport-loader%EF%BC%8Csupport-o-loader%E4%B8%AD%E7%9A%84encodings%E5%92%8Clabels"><span class="toc-number">3.2.1.</span> <span class="toc-text">获取train_loader，support_loader，support_o_loader中的encodings和labels</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E6%89%80%E6%9C%89%E7%9A%84encodings%E5%92%8Clabels"><span class="toc-number">3.2.2.</span> <span class="toc-text">返回所有的encodings和labels</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#get-token-logits-and-labels"><span class="toc-number">3.3.</span> <span class="toc-text">get_token_logits_and_labels</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#get-rehearsal-prototype"><span class="toc-number">3.4.</span> <span class="toc-text">get_rehearsal_prototype()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%94%AF%E6%8C%81%E9%9B%86%E4%BB%A5%E5%8F%8A%E5%AE%83%E4%BB%AC%E7%9A%84encodings%E5%92%8Clabels"><span class="toc-number">3.4.1.</span> <span class="toc-text">加载支持集以及它们的encodings和labels</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E7%B1%BB%E5%88%AB%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="toc-number">3.4.2.</span> <span class="toc-text">计算类别相似度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E7%B1%BB%E5%88%AB%E7%9B%B8%E4%BC%BC%E5%BA%A6%E5%88%97%E8%A1%A8"><span class="toc-number">3.4.3.</span> <span class="toc-text">返回类别相似度列表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">定义模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MySftBertModel"><span class="toc-number">4.1.</span> <span class="toc-text">MySftBertModel()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96-init"><span class="toc-number">4.1.1.</span> <span class="toc-text">初始化 init</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD-forward"><span class="toc-number">4.1.2.</span> <span class="toc-text">前向传播 forward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%BF%94%E5%9B%9E-loss-features-enc-features-logits"><span class="toc-number">4.1.3.</span> <span class="toc-text">3. 返回 loss, features_enc, features, logits</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">训练和评估模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#train-and-eval"><span class="toc-number">5.1.</span> <span class="toc-text">train_and_eval( )</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E4%B8%8A%E4%B8%80%E8%BD%AE%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E3%80%81%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%88%86%E8%AF%8D%E5%99%A8"><span class="toc-number">5.1.1.</span> <span class="toc-text">加载上一轮预训练的参数配置、模型和分词器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E8%AE%AD%E7%BB%83%E9%9B%86"><span class="toc-number">5.1.2.</span> <span class="toc-text">获取训练集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E6%97%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81"><span class="toc-number">5.1.3.</span> <span class="toc-text">获取旧模型的特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.1.4.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E5%BC%80%E5%8F%91%E9%9B%86%E4%B8%8A%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.1.5.</span> <span class="toc-text">在开发集上评估模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B"><span class="toc-number">5.1.6.</span> <span class="toc-text">在测试集上进行预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#teacher-evaluate"><span class="toc-number">5.2.</span> <span class="toc-text">teacher_evaluate()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E4%B8%8D%E5%90%8C%E6%A8%A1%E5%BC%8F%E8%AE%BE%E7%BD%AE%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8A%A0%E8%BD%BD%E5%99%A8"><span class="toc-number">5.2.1.</span> <span class="toc-text">根据不同模式设置数据集加载器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.2.2.</span> <span class="toc-text">评估模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E5%8E%9F%E5%9E%8B%E9%87%8D%E6%96%B0%E6%A0%87%E8%AE%B0%E9%98%88%E5%80%BC%E9%87%8D%E6%96%B0%E6%A0%87%E8%AE%B0%E6%97%A7%E5%AE%9E%E4%BD%93%E7%B1%BB"><span class="toc-number">5.2.3.</span> <span class="toc-text">用原型重新标记阈值重新标记旧实体类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E-logits-list-out-label-new-list"><span class="toc-number">5.2.4.</span> <span class="toc-text">返回 logits_list, out_label_new_list</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#evaluate"><span class="toc-number">5.3.</span> <span class="toc-text">evaluate ()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.3.1.</span> <span class="toc-text">读取数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E6%94%AF%E6%8C%81%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84embbedings%E5%92%8Clabels"><span class="toc-number">5.3.2.</span> <span class="toc-text">获取支持数据集的embbedings和labels</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E7%A7%8D%E9%87%8D%E6%96%B0%E6%A0%87%E8%AE%B0%E6%9D%A5%E8%87%AA%E6%97%A7%E7%B1%BB%E5%88%AB%E7%9A%84%E2%80%9CO%E2%80%9D%E7%9A%84%E7%AD%96%E7%95%A5"><span class="toc-number">5.3.3.</span> <span class="toc-text">三种重新标记来自旧类别的“O”的策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%9E%8B%E9%87%8D%E6%96%B0%E6%A0%87%E8%AE%B0"><span class="toc-number">5.3.3.1.</span> <span class="toc-text">使用原型重新标记</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%9C%80%E8%BF%91%E9%82%BB%E9%87%8D%E6%96%B0%E6%A0%87%E8%AE%B0"><span class="toc-number">5.3.3.2.</span> <span class="toc-text">使用最近邻重新标记</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%8E%9F%E6%9C%89%E6%A8%A1%E5%9E%8B%E9%87%8D%E6%96%B0%E6%A0%87%E8%AE%B0"><span class="toc-number">5.3.3.3.</span> <span class="toc-text">使用原有模型重新标记</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-number">5.3.4.</span> <span class="toc-text">保存预测结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-number">5.3.5.</span> <span class="toc-text">预测结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#train"><span class="toc-number">5.4.</span> <span class="toc-text">train()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E8%AE%AD%E7%BB%83%E6%80%BB%E6%AD%A5%E6%95%B0t-total%E5%92%8C%E8%AE%AD%E7%BB%83%E8%BD%AE%E6%95%B0num-train-epochs"><span class="toc-number">5.4.1.</span> <span class="toc-text">计算训练总步数t_total和训练轮数num_train_epochs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">5.4.2.</span> <span class="toc-text">配置优化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">5.4.3.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0"><span class="toc-number">5.4.4.</span> <span class="toc-text">评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E5%85%A8%E5%B1%80%E6%AD%A5%E6%95%B0%E5%92%8C%E5%B9%B3%E5%9D%87%E6%8D%9F%E5%A4%B1"><span class="toc-number">5.4.5.</span> <span class="toc-text">返回全局步数和平均损失</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NNClassification"><span class="toc-number">6.1.</span> <span class="toc-text">NNClassification()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#nn-classifier-dot-prototype"><span class="toc-number">6.1.1.</span> <span class="toc-text">nn_classifier_dot_prototype()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#get-top-emissions-with-th"><span class="toc-number">6.1.2.</span> <span class="toc-text">get_top_emissions_with_th()</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/08/16/shuju/%E5%9B%BE%E8%AE%BA/" title="图论"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(47).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图论"/></a><div class="content"><a class="title" href="/2024/08/16/shuju/%E5%9B%BE%E8%AE%BA/" title="图论">图论</a><time datetime="2024-08-15T16:00:00.000Z" title="发表于 2024-08-16 00:00:00">2024-08-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/15/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" title="实现横向联邦学习"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(46).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="实现横向联邦学习"/></a><div class="content"><a class="title" href="/2024/08/15/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" title="实现横向联邦学习">实现横向联邦学习</a><time datetime="2024-08-14T16:00:00.000Z" title="发表于 2024-08-15 00:00:00">2024-08-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/15/guancha/%E5%AF%BB%E4%BA%BA%E8%8F%B2%E8%8F%B2/" title="寻人|菲菲——甘肃兰州黄河公园（2004.夏）"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(9).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="寻人|菲菲——甘肃兰州黄河公园（2004.夏）"/></a><div class="content"><a class="title" href="/2024/08/15/guancha/%E5%AF%BB%E4%BA%BA%E8%8F%B2%E8%8F%B2/" title="寻人|菲菲——甘肃兰州黄河公园（2004.夏）">寻人|菲菲——甘肃兰州黄河公园（2004.夏）</a><time datetime="2024-08-14T16:00:00.000Z" title="发表于 2024-08-15 00:00:00">2024-08-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/01/JAVA/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Java学习笔记"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(13).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java学习笔记"/></a><div class="content"><a class="title" href="/2024/08/01/JAVA/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Java学习笔记">Java学习笔记</a><time datetime="2024-07-31T16:00:00.000Z" title="发表于 2024-08-01 00:00:00">2024-08-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/01/JAVA/Java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E5%8D%B7%E2%85%A0/" title="Java核心技术卷Ⅰ"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(47).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java核心技术卷Ⅰ"/></a><div class="content"><a class="title" href="/2024/08/01/JAVA/Java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E5%8D%B7%E2%85%A0/" title="Java核心技术卷Ⅰ">Java核心技术卷Ⅰ</a><time datetime="2024-07-31T16:00:00.000Z" title="发表于 2024-08-01 00:00:00">2024-08-01</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer_deal"><a class="deal_link" href="/972477867@qq.com" title="email"><i class="anzhiyufont anzhiyu-icon-envelope"></i></a><img class="footer_mini_logo" title="返回顶部" alt="返回顶部" onclick="anzhiyu.scrollToDest(0, 500)" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg" size="50px"/><a class="deal_link" target="_blank" rel="noopener" href="https://alive0103.github.io/" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://space.bilibili.com/372204786" title="Bilibili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div><div id="workboard"><img class="workSituationImg boardsign" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a07e38d9c307b7e9e81323.png" alt="欢迎来到我的小世界！~" title="欢迎来到我的小世界！~"/><div id="runtimeTextTip"></div></div><div id="anzhiyu-footer"><div class="footer-group"><div class="footer-title">服务</div><div class="footer-links"><a class="footer-item" title="51la统计" target="_blank" rel="noopener" href="https://v6.51.la/">51la统计</a><a class="footer-item" title="十年之约" target="_blank" rel="noopener" href="https://www.foreverblog.cn/">十年之约</a><a class="footer-item" title="开往" target="_blank" rel="noopener" href="https://github.com/travellings-link/travellings">开往</a></div></div><div class="footer-group"><div class="footer-title">导航</div><div class="footer-links"><a class="footer-item" title="Github" target="_blank" rel="noopener" href="https://github.com/Alive0103">Github</a><a class="footer-item" title="即刻短文" href="/essay/">即刻短文</a><a class="footer-item" title="友链文章" href="/fcircle/">友链文章</a><a class="footer-item" title="留言板" href="/comments/">留言板</a></div></div><div class="footer-group"><div class="footer-title-group"><div class="footer-title">友链</div><a class="random-friends-btn" id="footer-random-friends-btn" href="javascript:addFriendLinksInFooter();" title="换一批友情链接"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right"></i></a></div><div class="footer-links" id="friend-links-in-footer"></div></div></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title="博客框架为Hexo_v5.4.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Frame-Hexo.svg" alt="博客框架为Hexo_v5.4.0"/></a><a class="github-badge" target="_blank" href="https://blog.anheyu.com/" style="margin-inline:5px" data-title="本站使用AnZhiYu主题" title="本站使用AnZhiYu主题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.9/img/Theme-AnZhiYu-2E67D3.svg" alt="本站使用AnZhiYu主题"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2024 By <a class="footer-bar-link" href="/" title="奇冀" target="_blank">奇冀</a></div></div><div id="footer-type-tips"></div><div class="js-pjax"><script>function subtitleType () {
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      if (true) {
        const from = '出自 ' + data.from
        const sub = ["生活明朗&#44; 万物可爱&#44; 人间值得&#44; 未来可期."]
        sub.unshift(data.hitokoto, from)
        window.typed = new Typed('#footer-type-tips', {
          strings: sub,
          startDelay: 300,
          typeSpeed: 150,
          loop: true,
          backSpeed: 50,
        })
      } else {
        document.getElementById('footer-type-tips').innerHTML = data.hitokoto
      }
    })
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.cbd.int/typed.js@2.1.0/dist/typed.umd.js').then(subtitleType)
  }
} else {
  subtitleType()
}
</script></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">8</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/AssetsRepo" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/NLP-NER" title="智慧典藏(NLP-NER)"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="智慧典藏(NLP-NER)"/><span class="back-menu-item-text">智慧典藏(NLP-NER)</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/XDU-CS-lab" title="XDU-CS-lab"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="XDU-CS-lab"/><span class="back-menu-item-text">XDU-CS-lab</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于我</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/equipment/"><i class="anzhiyufont anzhiyu-icon-heartbeat faa-tada" style="font-size: 0.9em;"></i><span> 我的书屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Javaee/" style="font-size: 0.88rem; color: rgb(134, 165, 122);">Javaee<sup>2</sup></a><a href="/tags/MATLAB/" style="font-size: 0.88rem; color: rgb(131, 108, 60);">MATLAB<sup>1</sup></a><a href="/tags/NER/" style="font-size: 0.88rem; color: rgb(195, 179, 162);">NER<sup>16</sup></a><a href="/tags/STL/" style="font-size: 0.88rem; color: rgb(33, 63, 192);">STL<sup>2</sup></a><a href="/tags/anzhiyu/" style="font-size: 0.88rem; color: rgb(96, 95, 160);">anzhiyu<sup>1</sup></a><a href="/tags/pytorch/" style="font-size: 0.88rem; color: rgb(108, 168, 38);">pytorch<sup>1</sup></a><a href="/tags/%E5%AF%BB%E4%BA%BA%E5%90%AF%E4%BA%8B/" style="font-size: 0.88rem; color: rgb(102, 79, 15);">寻人启事<sup>1</sup></a><a href="/tags/%E8%A7%82%E7%8C%B9/" style="font-size: 0.88rem; color: rgb(94, 190, 51);">观猹<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%A7%91/" style="font-size: 0.88rem; color: rgb(87, 133, 195);">计科<sup>1</sup></a></div></div><hr/></div></div><div id="keyboard-tips"><div class="keyboardTitle">博客快捷键</div><div class="keybordList"><div class="keybordItem"><div class="keyGroup"><div class="key">shift K</div></div><div class="keyContent"><div class="content">关闭快捷键功能</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift A</div></div><div class="keyContent"><div class="content">打开/关闭中控台</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift M</div></div><div class="keyContent"><div class="content">播放/暂停音乐</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift D</div></div><div class="keyContent"><div class="content">深色/浅色显示模式</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift S</div></div><div class="keyContent"><div class="content">站内搜索</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift R</div></div><div class="keyContent"><div class="content">随机访问</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift H</div></div><div class="keyContent"><div class="content">返回首页</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift F</div></div><div class="keyContent"><div class="content">友链鱼塘</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift L</div></div><div class="keyContent"><div class="content">友链页面</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift P</div></div><div class="keyContent"><div class="content">关于本站</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift I</div></div><div class="keyContent"><div class="content">原版/本站右键菜单</div></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("04/01/2024 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2024 By 安知鱼 V1.6.12",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 奇冀 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script async="async">(function () {
  var grt = new Date("04/01/2024 00:00:00"); //设置网站上线时间
  var now = new Date();
  var dnum;
  var hnum;
  var mnum;
  var snum;
  var nowHour;

  // 计算并更新天数、小时数、分钟数和秒数
  function updateTime() {
    now = new Date(); // 更新 now 的值
    nowHour = now.getHours(); // 更新 nowHour 的值
    var days = (now - grt) / 1000 / 60 / 60 / 24;
    dnum = Math.floor(days);
    var hours = (now - grt) / 1000 / 60 / 60 - 24 * dnum;
    hnum = Math.floor(hours);
    if (String(hnum).length == 1) {
      hnum = "0" + hnum;
    }
    var minutes = (now - grt) / 1000 / 60 - 24 * 60 * dnum - 60 * hnum;
    mnum = Math.floor(minutes);
    if (String(mnum).length == 1) {
      mnum = "0" + mnum;
    }
    var seconds = (now - grt) / 1000 - 24 * 60 * 60 * dnum - 60 * 60 * hnum - 60 * mnum;
    snum = Math.round(seconds);
    if (String(snum).length == 1) {
      snum = "0" + snum;
    }
  }

  // 更新网页中显示的网站运行时间
  function updateHtml() {
    const footer = document.getElementById("footer");
    if (!footer) return
    let currentTimeHtml = "";
    if (nowHour < 18 && nowHour >= 9) {
      // 如果是上班时间，默认就是"安知鱼-上班摸鱼中.svg"图片，不需要更改
      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    } else {
      // 如果是下班时间，插入"安知鱼-下班啦.svg"图片
      let img = document.querySelector("#workboard .workSituationImg");
      if (img != null) {
        img.src = "https://pic.imgdb.cn/item/66a07e38d9c307b7e9e8134d.png";
        img.title = "下班了就该开开心心的玩耍";
        img.alt = "下班了就该开开心心的玩耍";
      }

      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    }

    if (document.getElementById("runtimeTextTip")) {
      document.getElementById("runtimeTextTip").innerHTML = currentTimeHtml;
    }
  }

  setInterval(() => {
    updateTime();
    updateHtml();
  }, 1000);
})();</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'pluRD6FBkCo5iajMaSIZPbZ8-gzGzoHsz',
      appKey: 'DEPAhIiN4akzk3dUFHvSzGL5',
      avatar: 'mp',
      serverURLs: 'https://plurd6fb.lc-cn-n1-shared.com',
      emojiMaps: {"tv_doge":"6ea59c827c414b4a2955fe79e0f6fd3dcd515e24.png","tv_亲亲":"a8111ad55953ef5e3be3327ef94eb4a39d535d06.png","tv_偷笑":"bb690d4107620f1c15cff29509db529a73aee261.png","tv_再见":"180129b8ea851044ce71caf55cc8ce44bd4a4fc8.png","tv_冷漠":"b9cbc755c2b3ee43be07ca13de84e5b699a3f101.png","tv_发怒":"34ba3cd204d5b05fec70ce08fa9fa0dd612409ff.png","tv_发财":"34db290afd2963723c6eb3c4560667db7253a21a.png","tv_可爱":"9e55fd9b500ac4b96613539f1ce2f9499e314ed9.png","tv_吐血":"09dd16a7aa59b77baa1155d47484409624470c77.png","tv_呆":"fe1179ebaa191569b0d31cecafe7a2cd1c951c9d.png","tv_呕吐":"9f996894a39e282ccf5e66856af49483f81870f3.png","tv_困":"241ee304e44c0af029adceb294399391e4737ef2.png","tv_坏笑":"1f0b87f731a671079842116e0991c91c2c88645a.png","tv_大佬":"093c1e2c490161aca397afc45573c877cdead616.png","tv_大哭":"23269aeb35f99daee28dda129676f6e9ea87934f.png","tv_委屈":"d04dba7b5465779e9755d2ab6f0a897b9b33bb77.png","tv_害羞":"a37683fb5642fa3ddfc7f4e5525fd13e42a2bdb1.png","tv_尴尬":"7cfa62dafc59798a3d3fb262d421eeeff166cfa4.png","tv_微笑":"70dc5c7b56f93eb61bddba11e28fb1d18fddcd4c.png","tv_思考":"90cf159733e558137ed20aa04d09964436f618a1.png","tv_惊吓":"0d15c7e2ee58e935adc6a7193ee042388adc22af.png"},
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.cbd.int/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.yydnas.cn/',
      region: 'ap-guangzhou',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.yydnas.cn/',
      region: 'ap-guangzhou',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  if ('Valine' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script src="https://cdn.cbd.int/blueimp-md5@2.19.0/js/md5.min.js"></script><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getIcon = (icon, mail) => {
    if (icon) return icon
    let defaultIcon = '?d=mp'
    let iconUrl = `https://gravatar.loli.net/avatar/${md5(mail.toLowerCase()) + defaultIcon}`
    return iconUrl
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const serverURL = 'https://plurd6fb.lc-cn-n1-shared.com'

    var settings = {
      "method": "GET",
      "headers": {
        "X-LC-Id": 'pluRD6FBkCo5iajMaSIZPbZ8-gzGzoHsz',
        "X-LC-Key": 'DEPAhIiN4akzk3dUFHvSzGL5',
        "Content-Type": "application/json"
      },
    }

    fetch(`${serverURL}/1.1/classes/Comment?limit=6&order=-createdAt`,settings)
      .then(response => response.json())
      .then(data => {
        const valineArray = data.results.map(function (e) {
          return {
            'avatar': getIcon(e.QQAvatar, e.mail),
            'content': changeContent(e.comment),
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.updatedAt,
          }
        })
        saveToLocal.set('valine-newest-comments', JSON.stringify(valineArray), 10/(60*24))
        generateHtml(valineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      }) 
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('valine-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "visitor@anheyu.com";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>