<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Few-Shot论文修改意见 | 奇冀の观猹录</title><meta name="keywords" content="NER"><meta name="author" content="奇冀"><meta name="copyright" content="奇冀"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Few-Shot论文修改意见"><meta name="application-name" content="Few-Shot论文修改意见"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="Few-Shot论文修改意见"><meta property="og:url" content="http://example.com/2024/09/24/NER/理论部分/index.html"><meta property="og:site_name" content="奇冀の观猹录"><meta property="og:description" content="发展现状里面分为3点，持续学习、增量学习和终身学习的差别不大，可浓缩为1点，并由此可以引出类增量学习的概念，第2点为类增量问题中缓解灾难性遗忘的方法，第3点为传统NER和类增量NER; 存在的问题里面，应尽可能指出目前类增量NER存在的主要问题，以区别于其他NLP任务的类增量学习，因此，目前提出的部"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://example.com/img/tu/img(28).jpg"><meta property="article:author" content="奇冀"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://example.com/img/tu/img(28).jpg"><meta name="description" content="发展现状里面分为3点，持续学习、增量学习和终身学习的差别不大，可浓缩为1点，并由此可以引出类增量学习的概念，第2点为类增量问题中缓解灾难性遗忘的方法，第3点为传统NER和类增量NER; 存在的问题里面，应尽可能指出目前类增量NER存在的主要问题，以区别于其他NLP任务的类增量学习，因此，目前提出的部"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://example.com/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: undefined,
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎回来！"},
  LA51: {"enable":true,"ck":"3IH9y4LmRJtzItks","LingQueMonitorID":"3IH9oXLUn9kZ7Y15"},
  greetingBox: {"enable":true,"default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋, 宝贝","startTime":12,"endTime":14},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"19点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://twikoo.yydnas.cn/',
  commentBarrageConfig:undefined,
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: {"mode":"both","api":"https://img2color-go.vercel.app/api?img=","cover_change":true},
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🏠 智能家居小能手","🔨 设计开发一条龙","🤝 专修交互与设计","🏃 脚踏实地行动派","🧱 团队小组发动机","✨ 多彩生活记录者"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    simplehomepage: false,
    post: true
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":true,"limitCount":50,"languages":{"author":"作者: 奇冀","link":"链接: ","source":"来源: 奇冀の观猹录","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: true,
  shortcutKey: {"enable":true,"delay":100,"shiftDelay":200},
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '奇冀の观猹录',
  title: 'Few-Shot论文修改意见',
  postAI: '',
  pageFillDescription: '摘要, 1.发展现状, 1. 1类增量学习, 1.1.1 传统学习方式的比较, 1.1.2 NER任务中的类增量学习, 1.2 类增量学习中缓解灾难性遗忘的方法, 1.3 传统NER与类增量NER的对比, 2.存在的问题, 2.1 灾难性遗忘问题, 2.2 标签不完整问题, 2.3 类别不平衡和冲突问题, 2.4 少样本学习问题, 2.5 过拟合问题, 3.理论背景, 3.1 类增量NER背景与挑战, 3.2 解决思路, 3.3 理论框架, 3.3.1 少样本学习, 3.3.2 知识蒸馏, 3.3.3 合成数据增强, 3.3.4 标签解释学习, 3.3.5 伪标签生成, 3.3.6 学习与回顾（LampR）, 3.4 理论方法总结, 4. 研究方法, 4.1 人脑学习机制, 4.2 框架设计, 4.2.1知识蒸馏, 4.2.2 合成数据增强, 4.2.3 标签解释学习, 4.2.4 伪标签生成, 4.2.5 学习与回顾, 4.3 创新点, 5 Experiment Setup, 5.1 dataset发展现状里面分为点持续学习增量学习和终身学习的差别不大可浓缩为点并由此可以引出类增量学习的概念第点为类增量问题中缓解灾难性遗忘的方法第点为传统和类增量存在的问题里面应尽可能指出目前类增量存在的主要问题以区别于其他任务的类增量学习因此目前提出的部分问题可能并不适用并缺乏了对少样本零样本的讨论也有部分问题存在因果联系可考虑浓缩在描述本研究的理论方法时重点描述为提出少样本条件下的类增量方法点出解决上述问题中的具体哪一个问题在描述设计研究方法的思路时给出在知识蒸馏基础上应用不同策略伪标签生成合成数据增强的思路是从哪些角度考虑的可以进一步缓解灾难性遗忘问题的最好能找到一个套用人脑学习机制的思路拔高一下主题标签解释学习也可以作为知识蒸馏的增强型策略按照这个框架可以往里面填充内容了组织文献时注意前后文献引用时的内在逻辑而不是简单的文献堆砌小问题要不要在研究方法设计部分加例子摘要随着深度学习技术的发展在命名实体识别任务中传统的持续学习与增量学习方法逐渐因为计算资源消耗大和容易产生灾难性遗忘问题而暴露其局限性为了解决这个问题有人提出了类增量学习使得模型在不访问旧类别数据的前提下接触新的实体类别时仍保持对旧类别的识别能力这种方法能够节省计算资源并在一定程度上缓解灾难性遗忘问题但面对长序列任务时对旧类别的遗忘问题依旧是一项挑战在这篇论文中我们提出了一种基于少样本条件下的类增量模型训练方法该方法的主要思想是将少样本学习的理论与问题结合起来利用知识蒸馏缓解增量中的灾难性遗忘问题并通过伪标签生成和合成数据增强来提高模型的少样本学习能力同时为了模拟人脑学习机制我们采用策略使模型回顾旧类别的知识以达到对新旧类别认知的平衡该方法提升了模型对新旧类别的平衡能力并在实践应用中表现出较强的适应性我们在中国军事数据集上对模型进行了测试测试结果表明我们的模型在缓解灾难性遗忘问题方面的表现有了显著的提高关键词自然实体识别少样本学习知识蒸馏伪标签生成一发展现状的修改缩减持续学习增量学习终身学习的区别可以将持续学习增量学习和终身学习这三者的区别浓缩为一个更简洁的介绍例如描述它们在目标上都类似即应对模型的逐步学习和更新以此引出类增量学习的概念将重点转向类增量学习的实际应用及其特殊性如在任务中的重要性修改示例类增量学习逐步取代了传统的持续学习和终身学习的概念特别是在命名实体识别任务中类增量学习适用于处理新实体类别的逐步引入和学习而无需访问旧类别的数据其目标是同时保持新旧类别的识别能力避免灾难性遗忘问题缓解灾难性遗忘的方法强调类增量问题中的关键挑战灾难性遗忘概述知识蒸馏方法伪标签生成等解决方案简要说明各自的优势修改示例类增量中的关键挑战是灾难性遗忘现有的主要解决方案包括知识蒸馏方法伪标签生成等知识蒸馏通过传递先前模型的知识来保持旧类别的识别能力而方法则通过合成数据增强训练进一步缓解灾难性遗忘传统与类增量的对比对比传统和类增量模型突出类增量中灾难性遗忘的问题及其特殊性如类标记不完整类别冲突等修改示例与传统的模型不同类增量需要逐步适应新的实体类别但往往无法访问旧类别的数据这导致了特定的挑战如灾难性遗忘类别间的混淆以及高昂的重新标注成本发展现状类增量学习随着深度学习技术的飞速发展传统的持续学习和增量学习方法逐渐暴露出其在实际应用中的局限性尤其在命名实体识别任务中模型需要能够适应不断变化的输入数据和新增的实体类别持续学习通常依赖于在所有任务或类别上进行重新训练这不仅计算资源消耗巨大还可能导致模型在引入新知识时遗忘已学的旧知识产生灾难性遗忘为了解决这一问题类增量学习应运而生类增量学习是逐步取代传统持续学习和增量学习的一种方法尤其在任务中表现得尤为重要其目标是使模型在接触新的实体类别时能够在不访问旧类别数据的情况下仍然保持对旧类别的识别能力这种能力使得类增量学习能够在不断引入新类别或任务时避免重新训练全模型节省计算资源并有效克服灾难性遗忘的问题传统学习方式的比较持续学习持续学习指的是模型逐渐学习多个任务而不丧失对先前任务的记忆其核心挑战在于如何在添加新知识的同时保持对旧任务性能的稳定然而持续学习难以有效解决灾难性遗忘尤其在跨领域或跨类别任务中模型的表现往往会显著下降增量学习增量学习与持续学习相似但强调在不断接触新数据时逐步学习和改进这种学习方式特别适用于数据快速增长且不可重复使用的场景然而增量学习同样面临对旧类别的遗忘问题特别是在任务序列较长时模型会逐渐失去对早期任务的记忆终身学习终身学习的理念是希望模型在整个生命周期内能够积累知识并应用于未来任务这种学习方式更关注长期的知识积累与迁移但与持续学习和增量学习类似灾难性遗忘仍然是核心难题这些学习方式的共同挑战在于灾难性遗忘即模型在学习新任务时会遗忘掉已经学习过的旧任务或类别因此类增量学习在此基础上提出了专门应对灾难性遗忘的方法特别适合那些需要逐步引入新类别的任务如命名实体识别任务中的类增量学习命名实体识别任务是信息抽取中的重要任务之一传统的模型通常假设所有实体类别在训练阶段都是已知的然而在实际应用中新的实体类别可能会随着时间的推移不断出现例如在军事领域医疗领域等专门的领域中不断出现新的实体类型这要求模型具备在不访问旧数据的情况下学习新实体的能力类增量的出现正是为了解决这一需求与传统不同类增量需要模型能够有效学习新类别同时尽可能保留对旧类别的记忆在这种场景中类增量学习不仅要求模型具有良好的泛化能力还必须较好地解决灾难性遗忘问题类增量学习中缓解灾难性遗忘的方法在类增量学习中灾难性遗忘是最主要的挑战之一模型在学习新任务时往往会逐渐遗忘掉之前学习过的任务尤其在没有访问旧数据的情况下这种现象在任务中尤为显著因为实体类别的重叠和相似性使得模型容易在识别新实体时丧失对旧实体的区分能力为了解决这一问题研究者提出了多种方法来缓解灾难性遗忘主要包括以下几种方法知识蒸馏知识蒸馏通过让新模型在训练时学习旧模型的输出从而保留旧模型对旧任务的知识对于类增量任务知识蒸馏可以在引入新实体类别时确保模型不会遗忘之前学习过的类别蒸馏的方法通常是在模型训练过程中引入额外的损失函数使得新模型的输出与旧模型的输出尽可能接近从而保持对旧类别的识别能力合成数据增强合成数据增强是一种通过生成新的数据样本来增强模型泛化能力的方法通过生成未标注的上下文文本并将其加入训练数据模型可以在不需要访问旧数据的情况下学习到新的类别合成数据增强的优势在于可以通过生成的上下文重新构建数据集从而实现数据的多样化和丰富化缓解数据不平衡和数据量不足的问题伪标签生成伪标签生成通过使用现有模型预测未标注数据中的实体类别从而生成带有标签的数据进行训练在类增量任务中伪标签生成可以帮助模型扩展数据集增强对新类别的学习能力这一方法的核心思想是使用模型预测新的实体类别产生伪标签并将这些带有伪标签的数据加入训练集中学习与回顾方法通过让模型在学习新类别的同时定期回顾旧类别从而确保模型不会忘记旧任务在类增量中方法通过使用合成数据进行回顾训练使得模型能够在新类别的学习过程中保持对旧类别的记忆该方法被证明比单纯的知识蒸馏更加有效尤其在数据不平衡的情况下能够显著提高模型的性能这些方法各有侧重但其共同目标是通过各种技术手段缓解类增量学习中的灾难性遗忘问题从而使模型在面对新任务时仍然能够保留旧任务的知识传统与类增量的对比传统模型在训练时通常假设所有的实体类别在训练过程中都是已知的模型一旦训练完成便无法再扩展新类别除非重新训练整个模型然而在实际应用中特别是在动态变化的环境中新的实体类别会不断出现这对传统模型提出了极大的挑战传统的局限性传统模型在处理新增实体类别时往往表现不佳原因在于它们无法增量学习新类别此外传统在引入新类别时需要访问之前的训练数据这在许多实际场景中是不现实的例如隐私数据无法存储或共享类增量的优势类增量模型能够在不访问旧数据的情况下引入新的实体类别同时保持对旧类别的识别能力它通过知识蒸馏伪标签生成和合成数据增强等技术手段确保模型能够逐步学习新的实体类别同时减少灾难性遗忘问题与传统相比类增量更具适应性尤其在需要频繁更新和扩展类别的任务中灾难性遗忘问题的特异性类增量中的灾难性遗忘问题比其他任务更加复杂因为实体类别之间的相似性更高新增类别往往与旧类别存在一定的重叠或相似之处导致模型在学习新类别时容易遗忘旧类别此外实体类别的数量和多样性也给模型带来了更大的学习难度可见类增量模型相较于传统模型在动态变化的任务环境下具有更强的适应能力同时其面临的灾难性遗忘问题也更加复杂这使得现有的解决方案仍有进一步优化的空间二存在问题部分的修改专注类增量特有的问题去掉一些并不适用的问题如高昂的重新标注成本等问题在类增量中相对不突出重点讨论当前类增量的主要挑战如灾难性遗忘标签不完整类别间冲突等修改示例类增量主要面临的问题包括灾难性遗忘即旧类别的知识在引入新类别后容易丢失标签不完整导致未标注的实体被错误分类为非实体类别间的混淆新旧类别之间的重叠使模型难以区分增加少样本零样本讨论增加少样本和零样本学习在类增量中的重要性并指出其解决的具体问题修改示例类增量中少样本和零样本学习也是一大挑战模型需要在数据极少甚至没有标注数据的情况下学习新类别这为系统的泛化能力提出了更高的要求现有方法往往难以兼顾这一点存在的问题类增量命名实体识别是一项复杂的任务面临着在不断引入新实体类别时的诸多独特挑战随着新实体的持续出现模型不仅需要灵活适应这些变化还必须保持对已学类别的准确识别以下将详细讨论该领域当前存在的主要问题并探讨这些问题与其他自然语言处理任务中类增量学习的差异这些分析有助于更清晰地理解类增量所面临的特定需求与挑战灾难性遗忘问题灾难性遗忘是类增量学习中最为典型和显著的问题也是类增量必须重点解决的核心挑战模型在学习新实体类别时容易遗忘掉之前已经学过的类别这是由于在增量学习过程中模型权重会调整为适应新任务而使旧任务的权重被覆盖这种现象在任务中尤为明显因为实体类别之间的边界较模糊新类别可能与旧类别存在高度相似性或重叠现有问题类增量中的灾难性遗忘不仅影响实体类别的识别准确性还可能导致模型对未标注类别的错误预测例如模型在学习一个新的炸弹实体时可能会误将之前学到的导弹实体标记为非实体灾难性遗忘不仅导致对旧类别的遗忘还可能引发类别混淆问题模型可能在新类别学习过程中将相似的旧类别混淆例如将军舰和航天设备错误地视为同一类别现有的方法如知识蒸馏数据增强等在一定程度上缓解了灾难性遗忘但它们仍然依赖于模型对数据分布的良好掌握且在数据稀少的情况下如少样本或零样本条件下效果有限解决方案多任务学习策略通过并行学习多个任务或实体类别以减少类别间的混淆和灾难性遗忘增强型知识蒸馏在类增量中结合标签解释学习等方法进一步优化知识蒸馏的效果确保旧类别知识不会轻易丢失动态模型更新机制动态更新模型权重赋予不同类别不同的重要性从而减少对旧类别知识的遗忘标签不完整问题传统的方法依赖于大量的标注数据但在实际场景中完整标注数据的获取成本高昂尤其是随着类别的不断扩展标注的难度和代价也随之增加在类增量任务中模型通常只能访问部分实体类别的数据导致数据集存在标签不完整的情况现有问题标签不完整导致模型在训练过程中对未标注的实体类别缺乏了解进而影响对新实体的识别在类增量场景下模型可能会将未见过的实体标记为非实体导致模型泛化能力下降标签不完整也加剧了类别间的不平衡问题新加入的类别通常数据较少而旧类别的数据更多这种不均衡使得模型在训练时更容易倾向于识别旧类别从而导致对新类别的识别能力不足解决方案伪标签生成通过在未标注的数据中生成伪标签使模型能够在有限的标注数据基础上进一步扩展数据集弥补标签不完整的缺陷数据增强和合成数据使用合成数据生成器生成更多样化的训练样本帮助模型在标签不完整的情况下更好地捕捉新类别的特征类别不平衡和冲突问题随着新类别的加入旧类别的数据量往往远多于新类别模型采样不均衡样本较少的新类更容易识别成旧类类别冲突问题主要体现在不同类别之间可能存在重叠且会引入多样化的实体类型较为相近的语义会造成模型的混淆不利于正确学习分类导致模型在区分相似类别时出现困扰现有问题类别不平衡容易导致模型偏向于预测频率较高的旧类别而忽视新类别特别是在新类别的数据非常少的情况下模型会对大类别过拟合而对小类别欠拟合类别冲突加剧了类别之间的混淆例如在军事领域导弹和炸弹可能在文本中表现出相似的上下文导致模型在识别时难以区分现有的模型通常假设类别之间是完全独立的但在类增量学习中类别之间往往有一定的关联性模型需要具备区分相似类别的能力解决方案数据重采样和权重调整通过对少数类进行过采样或者对不同类别分配不同的权重以缓解类别不平衡问题类间对比学习采用对比学习方法帮助模型更好地理解相似类别之间的区别减少类别冲突带来的影响少样本学习问题模型在引入新的实体类别时通常只有极少的数据甚至没有任何标注数据这种数据极少的情况在类增量学习中非常常见尤其是对于不断扩展的实体类别集合标注成本高昂且数据获取难度大现有问题少样本问题导致模型无法有效地学习新实体类别的特征这对于识别那些在训练中从未见过或见过很少样本的新实体来说尤其困难现有的方法通常需要大量标注数据进行训练因此在少样本或零样本条件下传统的监督学习方法表现不佳类增量在这种情况下必须依赖于迁移学习或其他数据扩展技术但这些技术在新类别的泛化能力上仍有局限解决方案基于迁移学习的少样本学习通过迁移学习将旧类别的知识迁移到新类别上从而实现少样本甚至零样本的任务基于生成模型的合成数据使用生成模型创建合成数据尤其是针对少样本或零样本条件下的数据不足问题增强模型的泛化能力过拟合问题在类增量任务中过拟合问题常常由于数据不平衡类别间相似性高等因素被进一步放大模型在学习过程中可能会过度依赖特定的类别特征导致在测试阶段的泛化能力下降现有问题新类别数据量通常较少而旧类别数据量较多模型容易在旧类别上过拟合特别是在类增量学习中模型不断扩展类别而每次新增的数据量非常有限这使得模型容易学习到新类别的噪声特征而忽略其一般化特征在标签不平衡或类别冲突较为明显的情况下模型会更倾向于记住某些特定的类别特征进而丧失对整体数据分布的把控解决方案正则化技术通过引入额外的正则化项来限制模型的复杂性避免过拟合正则化和技术在一定程度上可以缓解此问题早停法通过观察模型在验证集上的性能尽早停止训练避免模型在训练数据上过拟合综上类增量面临的主要挑战包括灾难性遗忘标签不完整类别不平衡类别冲突少样本学习以及模型过拟合等这些问题在与其他任务的类增量学习相比时显得更加复杂且独特必须针对这些问题提出专门的解决方案通过结合现有的技术如知识蒸馏伪标签生成合成数据增强等以及创新的模型设计有望有效应对这些挑战并在类增量中取得更好的结果三理论方法描述的修改强调少样本条件下的类增量方法重点描述本文提出的方法在少样本条件下如何应对类增量中的灾难性遗忘问题清晰地指出哪一种方法解决了上面提到的哪一个具体问题修改示例本研究提出了在少样本条件下有效的类增量方法旨在解决以下问题通过方法和知识蒸馏缓解灾难性遗忘通过伪标签生成和数据增强提高对新类别的识别能力即使在数据极少的情况下理论背景类增量背景与挑战随着信息提取任务在自然语言处理中的重要性日益增加命名实体识别任务作为信息抽取的核心任务之一面临着越来越复杂的应用场景在动态变化的环境中如军事医学或社交媒体等领域新实体类别的不断涌现使得传统模型难以应对传统的模型通常假设在训练阶段可以接触到所有实体类别的数据而在部署后无法轻易适应新的类别且会遗忘旧类别知识这些限制在实际应用中显得尤为突出特别是在标注数据有限的少样本条件下类增量学习通过逐步引入新类别的方式来克服这一局限允许模型在学习新类别的同时保持对旧类别的认知然而类增量任务中最主要的挑战包括灾难性遗忘标签不完整类别不平衡和少样本零样本学习问题这些问题使得模型在逐步扩展新类别时容易忘记旧类别或无法有效泛化新类别的特征解决思路本文旨在针对类增量中的上述挑战提出一种基于少样本条件下的类增量模型训练方法该方法通过结合知识蒸馏伪标签生成合成数据增强等技术手段从各方面缓解灾难性遗忘问题增强新类别的识别能力特别是在少样本甚至零样本的情况下具体解决方案如下灾难性遗忘通过知识蒸馏将旧类别知识转移到新模型中确保在学习新类别时不丢失对旧类别的记忆少样本学习通过伪标签生成和合成数据增强扩展少量的新类别样本增加模型对新类别的泛化能力特别是在数据稀缺或无法获取大量标注数据的场景中标签不完整与类别不平衡通过生成伪标签和合成数据解决数据集中由于标签不完整或类别数据不平衡引发的偏差问题使模型在面对不同类别时表现更加均衡理论框架少样本学习少样本学习是指在仅有极少数据样本的情况下模型仍能够对新任务进行有效学习的能力少样本学习的理论基础源于迁移学习和元学习其目标是通过从已有任务中学习到的知识迁移或泛化到新的任务上以减少对大量标注数据的需求在本文中少样本学习的理论与类增量结合起来主要目的是在引入新类别时由于标注成本高数据稀缺模型能够通过少量样本或零样本数据学习到新实体类别的特征同时通过结合伪标签生成与数据增强的方法扩展现有的训练数据从而进一步提高模型在少样本条件下的泛化能力知识蒸馏知识蒸馏是一种将复杂模型教师模型的知识传递给更简单模型学生模型的方法在类增量学习中知识蒸馏的作用是通过将旧模型的知识传递到新模型防止新模型在学习新类别时遗忘之前的类别知识在本文中知识蒸馏被用于缓解类增量中的灾难性遗忘问题通过对旧类别的知识进行蒸馏使新模型能够在学习新类别时仍然保持对旧类别的识别能力这一过程通过引入额外的损失函数强制新模型的输出与旧模型一致从而减少旧类别的知识遗忘特别是在少样本条件下知识蒸馏不仅有助于保持旧类别的记忆还能帮助模型更有效地利用新类别的有限数据针对灾难性遗忘问题知识蒸馏是解决灾难性遗忘的核心方法之一通过在模型训练时保留旧类别的知识防止新类别学习时的知识覆盖针对标签不完整问题通过蒸馏旧类别的知识模型在新数据缺少旧类别标签的情况下也能维持对旧类别的较高识别能力合成数据增强合成数据增强是通过生成合成样本来扩展训练数据集的一种技术通常用于应对数据稀缺和类别不平衡问题合成数据增强通过训练生成模型如或生成与原始数据分布类似的合成数据并将其用于训练以提高模型的泛化能力本文中合成数据增强主要用于少样本条件下的数据扩展和类别平衡通过生成未标注的上下文或样本模型可以在没有大量标注数据的情况下继续学习新类别的特征这种方法不仅增加了新类别的样本数量也使得模型对新类别的学习更加全面进而减轻类别不平衡带来的影响针对类别不平衡问题合成数据增强通过生成更多的新类别数据弥补了数据不平衡的现象使模型在训练时不会偏向旧类别针对少样本学习问题通过合成与新类别相关的上下文数据模型可以在数据不足的情况下进行更充分的学习提升对新类别的识别能力标签解释学习标签解释学习方法适用于解决少样本命名实体识别中的泛化问题为了应对少样本面临的仅凭少量的标注数据模型很难准确识别和分类新的命名实体这一挑战该方法通过在模型训练过程中引入多样化的实体类型及其详细的自然语言描述使模型能够更好地理解和泛化未见过的实体类型在训练阶段模型学习和理解这些标签的语义然后在少量示例的情况下将所学知识应用于识别和分类新的实体类型提升模型的跨域和跨语言泛化能力使其能够在未见过的领域或语言环境中依然表现出色有效应对少样本条件下的任务伪标签生成伪标签生成是一种半监督学习方法基本思路是利用现有模型预测未标注数据的标签生成伪标签并将这些带有伪标签的数据加入到训练集中从而扩展数据集规模本文利用伪标签生成方法扩展少样本数据集特别是在新实体类别数据稀缺的情况下通过使用已训练模型预测未标注数据中的实体类别将生成的伪标签与真实标注的数据混合使用增强模型对新类别的泛化能力这样可以有效缓解类增量中由于数据不足带来的问题针对少样本学习问题伪标签生成通过在新类别上生成更多带伪标签的数据扩大了数据集的规模有效提高了模型在少样本条件下的学习能力针对标签不完整问题当新数据缺少部分实体类别的标注时伪标签生成可以补全这些缺失的标签从而提高模型的学习效果学习与回顾通过模拟人类通过不断复习旧知识来加深记忆的机制在每个增量学习阶段结束后通过回顾旧类别的知识帮助模型保持对旧类别的认知在学习新类别数据之后模型会在增强后的数据集上进行再次训练以重新强化对旧类别的记忆学习与回顾策略不仅通过系统的复习和强化训练缓解了灾难性遗忘问题还通过丰富的训练数据支持了少样本学习的有效性这种结合使得模型在增量学习过程中更加灵活和稳健能够在新旧类别之间实现良好的平衡理论方法总结本文提出了一种综合知识蒸馏伪标签生成合成数据增强和的类增量方法重点解决类增量任务中的灾难性遗忘和少样本学习问题具体而言模型在每个增量阶段的学习过程中首先通过知识蒸馏保持对旧类别的认知避免灾难性遗忘然后使用伪标签生成来扩展少量的新类别数据增加数据规模最后通过合成数据增强进一步增加数据集的多样性和数量缓解类别不平衡及少样本问题四研究方法设计思路的修改引入人脑学习机制的类比增强设计思路的阐述结合人脑学习机制提升理论高度通过说明不同策略如何从不同角度缓解灾难性遗忘进一步提高该段内容的深度修改示例我们的方法设计基于人脑的学习机制知识蒸馏类似于人类在学习新信息时通过复习巩固旧知识而伪标签生成和策略则像人类在新情境下通过联想和类比进行推理和归纳从而提高对新知识的记忆和泛化能力解释各策略的作用详细说明不同策略伪标签生成数据增强是如何从不同角度缓解灾难性遗忘问题的修改示例我们在知识蒸馏的基础上分别通过策略复习旧类别的知识通过伪标签生成扩展少样本数据集通过合成数据增强整体数据的丰富性每种策略都从不同角度针对灾难性遗忘进行缓解确保模型在引入新类别时保持对旧类别的认知研究方法通过结合人脑学习机制的类比我们提出了一种基于少样本条件下的类增量方法该方法的核心思想是从人类学习的过程汲取灵感设计多种策略以缓解类增量学习中的灾难性遗忘少样本学习标签不完整及类别不平衡等问题我们使用了知识蒸馏伪标签生成合成数据增强和学习与回顾策略以确保模型在逐步引入新类别时能够同时保留旧类别的知识且在少样本条件下具备较好的泛化能力人脑学习机制人类学习新知识时通常依赖于复习旧知识推理和联想以及构建假设场景来提升记忆和理解能力类比于此我们的方法设计通过以下几个方面模拟了人脑学习的过程知识蒸馏这一策略类似于人类在学习新知识时通过不断复习来巩固已学知识通过知识蒸馏我们将旧模型的知识传递给新模型确保新模型在学习新类别的同时不会遗忘旧类别就像人类通过复习保持对旧知识的记忆一样知识蒸馏使得模型在新旧类别的学习中达到平衡伪标签生成伪标签生成则类似于人类通过联想和推理在不完全信息的情况下进行推测当人类面对不确定的情境时往往通过联想和类比做出预测和判断伪标签生成通过已训练模型预测未标注数据中的实体类别扩展数据集帮助模型在少样本或零样本条件下提升对新类别的识别能力学习与回顾策略策略模拟了人类通过反复回顾来提升记忆的过程人类在学习新知识时通常通过回顾之前学过的内容来增强记忆和理解策略在训练过程中通过回顾旧类别的知识帮助模型保持对旧类别的认知并确保新旧类别的平衡本文提出了在少样本条件下的类增量方法旨在解决类增量任务中的灾难性遗忘少样本学习标签不完整及类别不平衡等问题我们的研究方法主要包括三个核心步骤知识蒸馏伪标签生成和合成数据增强并在这些方法的基础上结合学习与回顾框架逐步构建类增量模型框架设计为了验证我们所提出方法的有效性本文使用了一个分步的增量学习框架在每一阶段中模型将逐步接触新的实体类别并学习在少量标注数据或零样本情况下识别新类别同时在不访问旧类别数据的前提下模型通过知识蒸馏伪标签生成和合成数据增强技术缓解对旧类别的遗忘核心思想是通过多步训练和逐步引入新类别使模型具备类增量学习的能力并能够在每次学习新类别时保持对旧类别的记忆能力尤其在少样本条件下提升模型的泛化性能为了解决类增量任务中的核心问题特别是灾难性遗忘和少样本学习本研究设计了以下几种方法知识蒸馏知识蒸馏的核心作用是缓解灾难性遗忘通过将旧模型对旧类别的知识蒸馏给新模型使新模型能够在学习新类别的同时保留对旧类别的记忆蒸馏过程确保了新模型输出与旧模型在旧类别上的输出保持一致从而避免了新知识覆盖旧知识的情况通过这种方法模型能够有效地在逐步引入新类别的过程中保留旧类别的识别能力训练过程中旧模型的输出即对旧类别的预测分布被用作教师模型新模型通过优化目标函数使其在学习新类别的同时保持输出与旧模型对旧类别的预测相一致损失函数包含两部分一是用于学习新类别的标准交叉熵损失二是用于保持旧类别知识的蒸馏损失后者通过缩小新旧模型在旧类别上的预测差异来实现对于每一个新类别的学习模型的总损失函数为是针对新类别的标准交叉熵损失是针对旧类别知识的蒸馏损失是平衡这两者的系数通过知识蒸馏模型可以有效保持旧模型对旧类别的识别能力在学习新类的同时保留旧类的特性可以很好地缓解由于安全性或存储问题使得数据对模型不可见导致的灾难性遗忘问题合成数据增强合成数据增强通过生成与新类别相关的合成样本来解决类别不平衡和少样本学习问题通过生成式模型生成与新类别相关的未标注上下文或样本将这些合成数据添加到训练集中使得模型能够接触到更多的新类别样本从而平衡新旧类别的数据分布这种方法类比于人类在理解新知识时构建假设场景进行模拟学习从而提升记忆和理解能力本文我们训练一个生成模型旨在生成与新类别相关的未标注上下文或样本通过训练模型我们能够捕捉到数据集中的潜在模式从而生成符合原始数据分布的合成文本这些文本中包含与新类别相关的实体而后将这些合成样本与真实标注数据和伪标签数据结合形成增强后的训练集最后使用包含合成数据的训练集进一步训练当前模型提高模型对新类别的适应能力首先使用原始数据集进行模型的训练通过大量的历史上下文数据能够学习到不同实体类别的特征和相互关系训练完成后模型能够生成与新类别相关的文本这些合成文本将包含新类别的实体从而扩展模型的训练样本通过模型生成的未标注数据在生成合成样本后我们将这些合成数据与真实标注数据和伪标签数据结合形成增强后的训练集是真实标注数据集是生成的文本数据针对类别不平衡问题合成数据增强通过生成更多的新类别样本有效缓解了类别不平衡的问题新类别的合成样本数量显著增加使得模型在训练时不至于过于偏向于旧类别确保每个类别都能得到足够的关注这种平衡的训练数据分布促使模型能够更好地学习新类别的特征提升对各类别的识别能力针对少样本学习问题合成数据的生成为新类别提供了额外的样本支持即使在标注数据稀缺的情况下生成的合成样本依然能够帮助模型学习到新类别的有效特征通过构建与新类别相关的上下文数据模型能够在数据不足的情况下进行更充分的学习提升对新类别的识别能力这一过程类似于人类在理解新知识时通过构建假设场景进行模拟学习从而增强记忆和理解能力标签解释学习少样本命名实体识别通过学习样本中被标注的实体来训练模型标签解释学习在于充分利用每个实体的标签信息把传统模型应用的标签如进行解释扩充通过学习和解释实体类型的自然语言描述即标签的描述信息在只有少量标注数据的情况下提高模型的泛化能力和性能首先模型通过学习现有实体类型的自然语言描述来掌握如何识别和分类文本中的命名实体具体来说模型在一个标注数据集上进行训练该数据集中包括了一组实体类型及其对应的描述例如标签可能对应描述为船标签可能对应描述为水面上移动的交通工具模型通过这些描述来建立标签与其含义之间的关联从而学会识别和分类这些实体类型然后将模型应用于新的未见过的实体类型通过提供新的实体类型描述和少量标注示例模型能够在少样本条件下执行任务在此阶段模型可以利用先前学到的标签解释知识将新的实体类型描述映射到相应的任务中这一过程允许模型在未见过的领域或实体类型上快速适应并进行命名实体识别通过增加标签解释学习阶段中实体类型的多样性和描述的详细程度能够显著提升模型在少样本条件下的性能尤其是在未见过的领域和跨语言环境中通过这种数据驱动的启发式优化模型在少样本任务中的表现得到了显著改善伪标签生成伪标签生成通过预测未标注数据中的实体类别并为其生成伪标签扩大数据集规模模型会使用前一阶段训练好的模型来预测新类别数据的伪标签并将这些伪标签数据与少量标注数据混合作为当前阶段的训练集这种方法特别适用于少样本或零样本的场景类似于人类通过联想和推理进行推测伪标签生成为模型提供了额外的数据资源扩展了训练集规模针对新类别的少量标注数据首先使用前一阶段的模型预测未标注数据中的潜在实体并生成伪标签给定输入数据模型预测的伪标签表示为是伪标签数据包含了未标注样本及其对应的伪标签而后将伪标签数据与真实标注数据结合形成增强版的训练集训练模型时使用伪标签扩展数据集结合标注数据集升模型对新类别的识别能力构建增强后的数据集使用增强后数据集训练新的模型使得模型能够接触到新类别的多种表示方式在训练过程中损失函数应同时考虑真实标注数据和伪标签数据的贡献损失函数为是针对真实标注数据的损失是针对伪标签数据的损失为超参数确保模型不仅从标注数据中学习还能从生成的伪标签中获取有价值的信息伪标签生成通过生成额外的伪标注数据极大扩展了可供训练的数据集帮助模型在数据稀缺的情况下学习新类别的特征这种方法使得即使在少量标注样本的情况下模型也能获得更多的训练数据提升对新类别的识别能力同时有效填补了数据集中未标注部分确保模型在学习新类别时能够更全面地学习到不同的特征这种填补使得模型可以在有限的标注数据下更好地捕捉新类别的多样性学习与回顾策略通过模仿人类的复习过程基于回顾旧知识的增量学习策略在每一阶段的学习过程中模型不仅学习新类别的数据通过定期回顾旧类别的数据或知识进行复习这种策略通过在回顾阶段使用合成数据和伪标签数据帮助模型保持对旧类别的记忆确保模型在引入新类别时仍然能够正确识别旧类别在本文中策略与知识蒸馏伪标签生成和合成数据增强相结合提升了模型对新类别和旧类别的适应能力模型训练可以分为两个阶段学习阶段模型首先在当前阶段的新类别数据上进行训练并通过知识蒸馏学习旧类别的知识训练目标是使模型尽可能准确地学习新类别并通过引入蒸馏损失函数来保持对旧类别的记忆学习阶段的损失函数为其中表示新类别的交叉熵损失表示旧模型与当前模型之间的蒸馏损失是平衡新知识学习与旧知识保留的权重回顾阶段在学习完新类别后策略通过合成数据增强和伪标签生成构建一个更为丰富的训练集帮助模型复习旧类别的知识增强的数据集包括两部分合成数据和伪标签数据通过生成模型生成的未标注上下文合成数据使得模型在接触到新类别的同时也能重新接触到旧类别的上下文信息同时使用现有模型预测的未标注数据生成带有伪标签的旧类别数据扩大旧类别数据集规模回顾阶段的损失函数为其中在增强数据集上计算的损失是基于旧类别的蒸馏损失是权衡回顾损失和蒸馏损失的超参数通过回顾旧知识模拟人类的学习行为不仅依赖于知识蒸馏还通过直接复习旧类别的数据主动学习强化对旧类别的记忆并减少新类别学习过程中旧知识的丢失创新点本文的方法设计通过模拟人脑的学习机制主要从两方面解决类增量中的主要问题设计思路和创新点包括从不同角度缓解灾难性遗忘知识蒸馏通过传递旧类别的知识有效防止新知识覆盖旧知识确保模型在学习新类别时不会遗忘旧类别策略通过复习旧类别知识进一步强化模型对旧类别的记忆避免模型在增量学习过程中丧失对旧类别的识别能力提升少样本学习的泛化能力伪标签生成通过在少样本条件下生成伪标注数据扩展了新类别的数据集帮助模型在标注数据不足的情况下提升对新类别的学习效果合成数据增强则通过生成更多的合成样本有效缓解了类别不平衡和少样本问题使模型能够接触到更多的训练数据提升对新类别的泛化能力本文的创新点在于通过结合多种策略模拟人类的学习与记忆机制提出了一种适用于少样本场景下的类增量解决方案有效缓解了类增量中的灾难性遗忘和少样本问题相比于传统方法我们的综合训练方法在少样本和零样本条件下表现更为优越不仅从理论上提升了模型对新旧类别的平衡能力在实践中也展现出较强的适应性能够在数据稀缺的情况下保持对新类别的良好学习效果解决了实际应用中常见的数据稀缺和标签不完整的问题具有重要的实践价值五实验设计标签解释学习这个应该要加进去我觉得虽然我们并没有用这个加一句由论文有力证明该方法可通过迁移学习有效缓解类间混淆问题而不会带来严重的负影响故我们在所有方法都加入标签解释学习方法而后对其他方法采用控制变量的方法进行实验标签解释学习作为增强策略在标签解释学习部分强调其与知识蒸馏的结合作为增强型策略应用于类增量修改示例标签解释学习可以作为知识蒸馏的增强策略通过使用标签的语义进行迁移学习使模型能够更好地理解和区分新类别六文献引用的逻辑组织调整文献引用的顺序和逻辑文献引用部分需要根据实际论述的逻辑顺序进行重新组织避免文献堆砌确保每一篇文献的引用都能够自然引出后续的论点和讨论修改示例相关工作引用部分可以按照知识蒸馏伪标签生成数据增强等方法的提出与演进顺序组织文献确保逻辑连贯大致描述一下我们参考了这些文献的哪些部分训练的方法相当于说把这个主要方法总结一下每个总结记得提及对应的文献们同时节相应位置给一个文献引用的标注即可第二节部分的问题浅浅看着标有文献提到相关问题或解决相关问题就标注一下主要参考文献来着那四个论文景士玲参考的论文伪标签的论文存在问题的论文',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-10-06 12:33:58',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/AssetsRepo" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/NLP-NER" title="智慧典藏(NLP-NER)"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="智慧典藏(NLP-NER)"/><span class="back-menu-item-text">智慧典藏(NLP-NER)</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/XDU-CS-lab" title="XDU-CS-lab"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="XDU-CS-lab"/><span class="back-menu-item-text">XDU-CS-lab</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">奇冀の观猹录</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"/><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于我</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/equipment/"><i class="anzhiyufont anzhiyu-icon-heartbeat faa-tada" style="font-size: 0.9em;"></i><span> 我的书屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://cdn.luogu.com.cn/upload/image_hosting/wyeaqekf.png" target="_blank"><img class="post-qr-code-img" alt="微信" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.luogu.com.cn/upload/image_hosting/wyeaqekf.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.luogu.com.cn/upload/image_hosting/dqwj733b.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.luogu.com.cn/upload/image_hosting/dqwj733b.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">音乐</div><span class="author-content-item-title">灵魂的碰撞💥</span></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="anzhiyufont anzhiyu-icon-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">12</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div><div class="console-btn-item" id="consoleKeyboard" onclick="anzhiyu.keyboardToggle()" title="快捷键开关"><a class="keyboard-switch"><i class="anzhiyufont anzhiyu-icon-keyboard"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/NER/" itemprop="url">NER</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/NER/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>NER</span></a></span></div></div><h1 class="post-title" itemprop="name headline">Few-Shot论文修改意见</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2024-09-23T16:00:00.000Z" title="发表于 2024-09-24 00:00:00">2024-09-24</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2024-10-06T04:33:58.091Z" title="更新于 2024-10-06 12:33:58">2024-10-06</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">14.4k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>43分钟</span></span><span class="post-meta-separator"></span><span class="leancloud_visitors" id="/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/" data-flag-title="Few-Shot论文修改意见"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span class="leancloud-visitors-count" title="访问量"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为西安"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>西安</span><span class="post-meta-separator"></span><span class="post-meta-commentcount"><i class="anzhiyufont anzhiyu-icon-comments post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/" itemprop="commentCount"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="/img/tu/img(28).jpg"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/"><header><a class="post-meta-categories" href="/categories/NER/" itemprop="url">NER</a><a href="/tags/NER/" tabindex="-1" itemprop="url">NER</a><h1 id="CrawlerTitle" itemprop="name headline">Few-Shot论文修改意见</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">奇冀</span><time itemprop="dateCreated datePublished" datetime="2024-09-23T16:00:00.000Z" title="发表于 2024-09-24 00:00:00">2024-09-24</time><time itemprop="dateCreated datePublished" datetime="2024-10-06T04:33:58.091Z" title="更新于 2024-10-06 12:33:58">2024-10-06</time></header><p>发展现状里面分为3点，持续学习、增量学习和终身学习的差别不大，可浓缩为1点，并由此可以引出类增量学习的概念，第2点为类增量问题中缓解灾难性遗忘的方法，第3点为传统NER和类增量NER;</p>
<p>存在的问题里面，应尽可能指出目前类增量NER存在的主要问题，以区别于其他NLP任务的类增量学习，因此，目前提出的部分问题可能并不适用，并缺乏了对少样本/零样本的讨论，也有部分问题存在因果联系，可考虑浓缩；</p>
<p>在描述本研究的理论方法时，重点描述为提出少样本条件下的类增量ner方法，点出解决上述问题中的具体哪一个问题；</p>
<p>在描述设计研究方法的思路时，给出在知识蒸馏基础上应用不同策略（L&amp;R、伪标签生成、合成数据增强）的思路，是从哪些角度考虑的，可以进一步缓解灾难性遗忘问题的，最好能找到一个套用人脑学习机制的思路，拔高一下主题。</p>
<p>标签解释学习也可以作为知识蒸馏的增强型策略</p>
<p>按照这个框架可以往里面填充内容了，related work组织文献时，注意前后文献引用时的内在逻辑，而不是简单的文献堆砌</p>
<p>==小问题：要不要在研究方法设计部分加例子？==</p>
<h1>摘要</h1>
<p>随着深度学习技术的发展，在命名实体识别（NER）任务中，传统的持续学习与增量学习方法逐渐因为计算资源消耗大和容易产生灾难性遗忘问题而暴露其局限性。为了解决这个问题，有人提出了类增量学习，使得模型在不访问旧类别数据的前提下，接触新的实体类别时仍保持对旧类别的识别能力。这种方法能够节省计算资源并在一定程度上缓解灾难性遗忘问题，但面对长序列任务时对旧类别的遗忘问题依旧是一项挑战。在这篇论文中，我们提出了一种基于少样本条件下的类增量NER模型训练方法。该方法的主要思想是将少样本学习的理论与NER问题结合起来：利用知识蒸馏缓解增量NER中的灾难性遗忘问题，并通过伪标签生成和合成数据增强来提高模型的少样本学习能力。同时，为了模拟人脑学习机制，我们采用L&amp;R策略使模型回顾旧类别的知识以达到对新旧类别认知的平衡。该方法提升了模型对新旧类别的平衡能力，并在实践应用中表现出较强的适应性。我们在中国军事数据集上对模型进行了测试。测试结果表明，我们的模型在缓解灾难性遗忘问题方面的表现有了显著的提高。</p>
<p>关键词：自然实体识别；少样本学习；知识蒸馏；伪标签生成</p>
<p>一. 发展现状的修改</p>
<ol>
<li>
<p><strong>缩减持续学习、增量学习、终身学习的区别</strong>：</p>
<ul>
<li>可以将“持续学习”、“增量学习”和“终身学习”这三者的区别浓缩为一个更简洁的介绍。例如，描述它们在目标上都类似，即应对模型的逐步学习和更新，以此引出类增量学习的概念。将重点转向类增量学习的实际应用及其特殊性，如在NER任务中的重要性。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>类增量学习逐步取代了传统的持续学习和终身学习的概念，特别是在命名实体识别（NER）任务中，类增量学习适用于处理新实体类别的逐步引入和学习，而无需访问旧类别的数据。其目标是同时保持新旧类别的识别能力，避免灾难性遗忘问题。</p>
</blockquote>
</li>
<li>
<p><strong>缓解灾难性遗忘的方法</strong>：</p>
<ul>
<li>强调类增量问题中的关键挑战——灾难性遗忘。概述知识蒸馏、L&amp;R方法、伪标签生成等解决方案，简要说明各自的优势。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>类增量NER中的关键挑战是灾难性遗忘，现有的主要解决方案包括知识蒸馏、L&amp;R方法、伪标签生成等。知识蒸馏通过传递先前模型的知识来保持旧类别的识别能力，而L&amp;R方法则通过合成数据增强训练，进一步缓解灾难性遗忘。</p>
</blockquote>
</li>
<li>
<p><strong>传统NER与类增量NER的对比</strong>：</p>
<ul>
<li>对比传统NER和类增量NER模型，突出类增量NER中灾难性遗忘的问题及其特殊性，如类标记不完整、类别冲突等。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>与传统的NER模型不同，类增量NER需要逐步适应新的实体类别，但往往无法访问旧类别的数据。这导致了特定的挑战，如灾难性遗忘、类别间的混淆以及高昂的重新标注成本。</p>
</blockquote>
</li>
</ol>
<h1>1.发展现状</h1>
<h2 id="1-1类增量学习">1. 1类增量学习</h2>
<p>随着深度学习技术的飞速发展，传统的持续学习和增量学习方法逐渐暴露出其在实际应用中的局限性。尤其在命名实体识别（NER）任务中，模型需要能够适应不断变化的输入数据和新增的实体类别。持续学习通常依赖于在所有任务或类别上进行重新训练，这不仅计算资源消耗巨大，还可能导致模型在引入新知识时遗忘已学的旧知识，产生<strong>灾难性遗忘</strong>（Catastrophic Forgetting）。</p>
<p>为了解决这一问题，类增量学习（CIL）应运而生。类增量学习是逐步取代传统持续学习和增量学习的一种方法，尤其在NER任务中表现得尤为重要。其目标是使模型在接触新的实体类别时，能够在不访问旧类别数据的情况下，仍然保持对旧类别的识别能力。这种能力使得类增量学习能够在不断引入新类别或任务时，避免重新训练全模型，节省计算资源，并有效克服灾难性遗忘的问题。</p>
<h3 id="1-1-1-传统学习方式的比较">1.1.1 传统学习方式的比较</h3>
<ul>
<li><strong>持续学习（Continual Learning）</strong>：持续学习指的是模型逐渐学习多个任务而不丧失对先前任务的记忆。其核心挑战在于如何在添加新知识的同时，保持对旧任务性能的稳定。然而，持续学习难以有效解决灾难性遗忘，尤其在跨领域或跨类别任务中，模型的表现往往会显著下降。</li>
<li><strong>增量学习（Incremental Learning）</strong>：增量学习与持续学习相似，但强调在不断接触新数据时逐步学习和改进。这种学习方式特别适用于数据快速增长且不可重复使用的场景。然而，增量学习同样面临对旧类别的遗忘问题，特别是在任务序列较长时，模型会逐渐失去对早期任务的记忆。</li>
<li><strong>终身学习（Lifelong Learning）</strong>：终身学习的理念是希望模型在整个生命周期内能够积累知识并应用于未来任务。这种学习方式更关注长期的知识积累与迁移，但与持续学习和增量学习类似，灾难性遗忘仍然是核心难题。</li>
</ul>
<p>这些学习方式的共同挑战在于<strong>灾难性遗忘</strong>（Catastrophic Forgetting），即模型在学习新任务时会遗忘掉已经学习过的旧任务或类别。因此，类增量学习在此基础上提出了专门应对灾难性遗忘的方法，特别适合那些需要逐步引入新类别的任务，如命名实体识别（NER）。</p>
<h3 id="1-1-2-NER任务中的类增量学习">1.1.2 NER任务中的类增量学习</h3>
<p>命名实体识别任务是信息抽取中的重要任务之一。传统的NER模型通常假设所有实体类别在训练阶段都是已知的，然而在实际应用中，新的实体类别可能会随着时间的推移不断出现。例如，在军事领域、医疗领域等专门的领域中，不断出现新的实体类型，这要求NER模型具备在不访问旧数据的情况下学习新实体的能力。</p>
<p>类增量NER的出现正是为了解决这一需求。与传统NER不同，类增量NER需要模型能够有效学习新类别，同时尽可能保留对旧类别的记忆。在这种场景中，类增量学习不仅要求模型具有良好的泛化能力，还必须较好地解决灾难性遗忘问题。</p>
<h2 id="1-2-类增量学习中缓解灾难性遗忘的方法">1.2 类增量学习中缓解灾难性遗忘的方法</h2>
<p>在类增量学习中，灾难性遗忘是最主要的挑战之一。模型在学习新任务时，往往会逐渐遗忘掉之前学习过的任务，尤其在没有访问旧数据的情况下。这种现象在NER任务中尤为显著，因为实体类别的重叠和相似性使得模型容易在识别新实体时丧失对旧实体的区分能力。</p>
<p>为了解决这一问题，研究者提出了多种方法来缓解灾难性遗忘，主要包括以下几种方法：</p>
<ul>
<li><strong>知识蒸馏（Knowledge Distillation）</strong>：知识蒸馏通过让新模型在训练时学习旧模型的输出，从而保留旧模型对旧任务的知识。对于类增量NER任务，知识蒸馏可以在引入新实体类别时，确保模型不会遗忘之前学习过的类别。蒸馏的方法通常是在模型训练过程中引入额外的损失函数，使得新模型的输出与旧模型的输出尽可能接近，从而保持对旧类别的识别能力。</li>
<li><strong>合成数据增强（Synthetic Data Augmentation）</strong>：合成数据增强是一种通过生成新的数据样本来增强模型泛化能力的方法。通过生成未标注的上下文文本并将其加入训练数据，模型可以在不需要访问旧数据的情况下学习到新的类别。合成数据增强的优势在于可以通过生成的上下文重新构建数据集，从而实现数据的多样化和丰富化，缓解数据不平衡和数据量不足的问题。</li>
<li><strong>伪标签生成（Pseudo-labeling）</strong>：伪标签生成通过使用现有模型预测未标注数据中的实体类别，从而生成带有标签的数据进行训练。在类增量NER任务中，伪标签生成可以帮助模型扩展数据集，增强对新类别的学习能力。这一方法的核心思想是使用模型预测新的实体类别，产生“伪标签”，并将这些带有伪标签的数据加入训练集中。</li>
<li><strong>学习与回顾（Learn &amp; Review, L&amp;R）</strong>：L&amp;R方法通过让模型在学习新类别的同时，定期回顾旧类别，从而确保模型不会忘记旧任务。在类增量NER中，L&amp;R方法通过使用合成数据进行回顾训练，使得模型能够在新类别的学习过程中保持对旧类别的记忆。该方法被证明比单纯的知识蒸馏更加有效，尤其在数据不平衡的情况下，能够显著提高模型的性能。</li>
</ul>
<p>这些方法各有侧重，但其共同目标是通过各种技术手段缓解类增量学习中的灾难性遗忘问题，从而使模型在面对新任务时，仍然能够保留旧任务的知识。</p>
<h2 id="1-3-传统NER与类增量NER的对比">1.3 传统NER与类增量NER的对比</h2>
<p>传统NER模型在训练时，通常假设所有的实体类别在训练过程中都是已知的。模型一旦训练完成，便无法再扩展新类别，除非重新训练整个模型。然而，在实际应用中，特别是在动态变化的环境中，新的实体类别会不断出现，这对传统NER模型提出了极大的挑战。</p>
<ul>
<li><strong>传统NER的局限性</strong>：传统NER模型在处理新增实体类别时往往表现不佳，原因在于它们无法增量学习新类别。此外，传统NER在引入新类别时，需要访问之前的训练数据，这在许多实际场景中是不现实的（例如，隐私数据无法存储或共享）。</li>
<li><strong>类增量NER的优势</strong>：类增量NER模型能够在不访问旧数据的情况下引入新的实体类别，同时保持对旧类别的识别能力。它通过知识蒸馏、伪标签生成和合成数据增强等技术手段，确保模型能够逐步学习新的实体类别，同时减少灾难性遗忘问题。与传统NER相比，类增量NER更具适应性，尤其在需要频繁更新和扩展类别的任务中。</li>
<li><strong>灾难性遗忘问题的特异性</strong>：类增量NER中的灾难性遗忘问题比其他任务更加复杂，因为实体类别之间的相似性更高。新增类别往往与旧类别存在一定的重叠或相似之处，导致模型在学习新类别时容易遗忘旧类别。此外，实体类别的数量和多样性也给模型带来了更大的学习难度。</li>
</ul>
<p>可见，类增量NER模型相较于传统NER模型在动态、变化的任务环境下具有更强的适应能力，同时其面临的灾难性遗忘问题也更加复杂，这使得现有的解决方案仍有进一步优化的空间。</p>
<p>二. 存在问题部分的修改</p>
<ol>
<li>
<p><strong>专注类增量NER特有的问题</strong>：</p>
<ul>
<li>去掉一些并不适用的问题，如“高昂的重新标注成本”等问题在类增量NER中相对不突出。重点讨论当前类增量NER的主要挑战，如灾难性遗忘、标签不完整、类别间冲突等。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>类增量NER主要面临的问题包括：1）灾难性遗忘，即旧类别的知识在引入新类别后容易丢失；2）标签不完整，导致未标注的实体被错误分类为非实体；3）类别间的混淆，新旧类别之间的重叠使模型难以区分。</p>
</blockquote>
</li>
<li>
<p><strong>增加少样本/零样本讨论</strong>：</p>
<ul>
<li>增加少样本和零样本学习在类增量NER中的重要性，并指出其解决的具体问题。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>类增量NER中，少样本和零样本学习也是一大挑战，模型需要在数据极少甚至没有标注数据的情况下学习新类别。这为NER系统的泛化能力提出了更高的要求，现有方法往往难以兼顾这一点。</p>
</blockquote>
</li>
</ol>
<h1>2.存在的问题</h1>
<p>类增量命名实体识别（NER）是一项复杂的任务，面临着在不断引入新实体类别时的诸多独特挑战。随着新实体的持续出现，模型不仅需要灵活适应这些变化，还必须保持对已学类别的准确识别。以下将详细讨论该领域当前存在的主要问题，并探讨这些问题与其他自然语言处理（NLP）任务中类增量学习的差异。这些分析有助于更清晰地理解类增量NER所面临的特定需求与挑战。</p>
<h2 id="2-1-灾难性遗忘问题">2.1 <strong>灾难性遗忘问题</strong></h2>
<p>灾难性遗忘是类增量学习中最为典型和显著的问题，也是类增量NER必须重点解决的核心挑战。模型在学习新实体类别时，容易遗忘掉之前已经学过的类别，这是由于在增量学习过程中，模型权重会调整为适应新任务，而使旧任务的权重被覆盖。这种现象在NER任务中尤为明显，因为实体类别之间的边界较模糊，新类别可能与旧类别存在高度相似性或重叠。</p>
<p><strong>现有问题：</strong></p>
<ul>
<li>类增量NER中的灾难性遗忘不仅影响实体类别的识别准确性，还可能导致模型对未标注类别的错误预测。例如，模型在学习一个新的“炸弹”实体时，可能会误将之前学到的“导弹”实体标记为非实体。</li>
<li>灾难性遗忘不仅导致对旧类别的遗忘，还可能引发类别混淆问题。模型可能在新类别学习过程中，将相似的旧类别混淆，例如将“军舰”和“航天设备”错误地视为同一类别。</li>
<li>现有的方法（如知识蒸馏、数据增强等）在一定程度上缓解了灾难性遗忘，但它们仍然依赖于模型对数据分布的良好掌握，且在数据稀少的情况下（如少样本或零样本条件下），效果有限。</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li><strong>多任务学习策略</strong>：通过并行学习多个任务或实体类别，以减少类别间的混淆和灾难性遗忘。</li>
<li><strong>增强型知识蒸馏</strong>：在类增量NER中，结合标签解释学习等方法，进一步优化知识蒸馏的效果，确保旧类别知识不会轻易丢失。</li>
<li><strong>动态模型更新机制</strong>：动态更新模型权重，赋予不同类别不同的重要性，从而减少对旧类别知识的遗忘。</li>
</ul>
<h2 id="2-2-标签不完整问题">2.2 <strong>标签不完整问题</strong></h2>
<p>传统的方法依赖于大量的标注数据，但在实际场景中，完整标注数据的获取成本高昂，尤其是随着类别的不断扩展，标注的难度和代价也随之增加。在类增量NER任务中，模型通常只能访问部分实体类别的数据，导致数据集存在标签不完整的情况。</p>
<p><strong>现有问题：</strong></p>
<ul>
<li>标签不完整导致模型在训练过程中对未标注的实体类别缺乏了解，进而影响对新实体的识别。在类增量场景下，模型可能会将未见过的实体标记为非实体，导致模型泛化能力下降。</li>
<li>标签不完整也加剧了类别间的不平衡问题。新加入的类别通常数据较少，而旧类别的数据更多，这种不均衡使得模型在训练时更容易倾向于识别旧类别，从而导致对新类别的识别能力不足。</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li><strong>伪标签生成</strong>：通过在未标注的数据中生成伪标签，使模型能够在有限的标注数据基础上进一步扩展数据集，弥补标签不完整的缺陷。</li>
<li><strong>数据增强和合成数据</strong>：使用合成数据生成器生成更多样化的训练样本，帮助模型在标签不完整的情况下更好地捕捉新类别的特征。</li>
</ul>
<h2 id="2-3-类别不平衡和冲突问题">2.3 <strong>类别不平衡和冲突问题</strong></h2>
<p>随着新类别的加入，旧类别的数据量往往远多于新类别，模型采样不均衡，样本较少的新类更容易识别成旧类。类别冲突问题主要体现在不同类别之间可能存在重叠，且会引入多样化的实体类型，较为相近的语义会造成模型的混淆，不利于正确学习分类，导致模型在区分相似类别时出现困扰。</p>
<p><strong>现有问题：</strong></p>
<ul>
<li>类别不平衡容易导致模型偏向于预测频率较高的旧类别，而忽视新类别，特别是在新类别的数据非常少的情况下。模型会对大类别过拟合，而对小类别欠拟合。</li>
<li>类别冲突加剧了类别之间的混淆。例如，在军事领域，“导弹”和“炸弹”可能在文本中表现出相似的上下文，导致模型在识别时难以区分。</li>
<li>现有的NER模型通常假设类别之间是完全独立的，但在类增量学习中，类别之间往往有一定的关联性，模型需要具备区分相似类别的能力。</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li><strong>数据重采样和权重调整</strong>：通过对少数类进行过采样，或者对不同类别分配不同的权重，以缓解类别不平衡问题。</li>
<li><strong>类间对比学习</strong>：采用对比学习方法，帮助模型更好地理解相似类别之间的区别，减少类别冲突带来的影响。</li>
</ul>
<h2 id="2-4-少样本学习问题">2.4 <strong>少样本学习问题</strong></h2>
<p>模型在引入新的实体类别时，通常只有极少的数据，甚至没有任何标注数据。这种数据极少的情况在类增量学习中非常常见，尤其是对于不断扩展的实体类别集合，标注成本高昂且数据获取难度大。</p>
<p><strong>现有问题：</strong></p>
<ul>
<li>少样本问题导致模型无法有效地学习新实体类别的特征，这对于识别那些在训练中从未见过或见过很少样本的新实体来说，尤其困难。</li>
<li>现有的NER方法通常需要大量标注数据进行训练，因此在少样本或零样本条件下，传统的监督学习方法表现不佳。</li>
<li>类增量NER在这种情况下必须依赖于迁移学习或其他数据扩展技术，但这些技术在新类别的泛化能力上仍有局限。</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li><strong>基于迁移学习的少样本学习</strong>：通过迁移学习将旧类别的知识迁移到新类别上，从而实现少样本甚至零样本的NER任务。</li>
<li><strong>基于生成模型的合成数据</strong>：使用生成模型创建合成数据，尤其是针对少样本或零样本条件下的数据不足问题，增强模型的泛化能力。</li>
</ul>
<h2 id="2-5-过拟合问题">2.5 <strong>过拟合问题</strong></h2>
<p>在类增量NER任务中，过拟合问题常常由于数据不平衡、类别间相似性高等因素被进一步放大，模型在学习过程中可能会过度依赖特定的类别特征，导致在测试阶段的泛化能力下降。</p>
<p><strong>现有问题：</strong></p>
<ul>
<li>新类别数据量通常较少，而旧类别数据量较多，模型容易在旧类别上过拟合。特别是在类增量学习中，模型不断扩展类别，而每次新增的数据量非常有限，这使得模型容易学习到新类别的噪声特征，而忽略其一般化特征。</li>
<li>在标签不平衡或类别冲突较为明显的情况下，模型会更倾向于记住某些特定的类别特征，进而丧失对整体数据分布的把控。</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li>
<p><strong>正则化技术</strong>：通过引入额外的正则化项来限制模型的复杂性，避免过拟合。L2正则化和dropout技术在一定程度上可以缓解此问题。</p>
</li>
<li>
<p><strong>早停法</strong>：通过观察模型在验证集上的性能，尽早停止训练，避免模型在训练数据上过拟合。</p>
</li>
</ul>
<p>综上，类增量NER面临的主要挑战包括灾难性遗忘、标签不完整、类别不平衡、类别冲突、少样本学习以及模型过拟合等。这些问题在与其他NLP任务的类增量学习相比时显得更加复杂且独特，必须针对这些问题提出专门的解决方案。通过结合现有的技术（如知识蒸馏、伪标签生成、合成数据增强等）以及创新的模型设计，有望有效应对这些挑战，并在类增量NER中取得更好的结果。</p>
<p>三. 理论方法描述的修改</p>
<ol>
<li>
<p><strong>强调少样本条件下的类增量NER方法</strong>：</p>
<ul>
<li>重点描述本文提出的方法在少样本条件下如何应对类增量NER中的灾难性遗忘问题。清晰地指出哪一种方法解决了上面提到的哪一个具体问题。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>本研究提出了在少样本条件下有效的类增量NER方法，旨在解决以下问题：通过L&amp;R方法和知识蒸馏，缓解灾难性遗忘；通过伪标签生成和数据增强，提高对新类别的识别能力，即使在数据极少的情况下。</p>
</blockquote>
</li>
</ol>
<h1>3.理论背景</h1>
<h2 id="3-1-类增量NER背景与挑战">3.1 类增量NER背景与挑战</h2>
<p>随着信息提取任务在自然语言处理（NLP）中的重要性日益增加，命名实体识别（NER）任务作为信息抽取的核心任务之一，面临着越来越复杂的应用场景。在动态变化的环境中，如军事、医学或社交媒体等领域，新实体类别的不断涌现使得传统NER模型难以应对。传统的NER模型通常假设在训练阶段可以接触到所有实体类别的数据，而在部署后无法轻易适应新的类别，且会遗忘旧类别知识。这些限制在实际应用中显得尤为突出，特别是在标注数据有限的少样本条件下。</p>
<p>类增量学习通过逐步引入新类别的方式来克服这一局限，允许模型在学习新类别的同时保持对旧类别的认知。然而，类增量NER任务中最主要的挑战包括<strong>灾难性遗忘</strong>、<strong>标签不完整</strong>、<strong>类别不平衡</strong>和<strong>少样本/零样本学习问题</strong>。这些问题使得模型在逐步扩展新类别时，容易忘记旧类别或无法有效泛化新类别的特征。</p>
<h2 id="3-2-解决思路">3.2 解决思路</h2>
<p>本文旨在针对类增量NER中的上述挑战，提出一种基于少样本条件下的类增量NER模型训练方法。该方法通过结合知识蒸馏、伪标签生成、合成数据增强等技术手段，从各方面缓解灾难性遗忘问题，增强新类别的识别能力，特别是在少样本甚至零样本的情况下。具体解决方案如下：</p>
<ul>
<li><strong>灾难性遗忘</strong>：通过知识蒸馏，将旧类别知识转移到新模型中，确保在学习新类别时不丢失对旧类别的记忆。</li>
<li><strong>少样本学习</strong>：通过伪标签生成和合成数据增强，扩展少量的新类别样本，增加模型对新类别的泛化能力，特别是在数据稀缺或无法获取大量标注数据的场景中。</li>
<li><strong>标签不完整与类别不平衡</strong>：通过生成伪标签和合成数据，解决数据集中由于标签不完整或类别数据不平衡引发的偏差问题，使模型在面对不同类别时表现更加均衡。</li>
</ul>
<h2 id="3-3-理论框架">3.3 理论框架</h2>
<h3 id="3-3-1-少样本学习">3.3.1 少样本学习</h3>
<p>少样本学习（Few-shot Learning，FSL）是指在仅有极少数据样本的情况下，模型仍能够对新任务进行有效学习的能力。少样本学习的理论基础源于迁移学习和元学习，其目标是通过从已有任务中学习到的知识迁移或泛化到新的任务上，以减少对大量标注数据的需求。</p>
<p>在本文中，少样本学习的理论与类增量NER结合起来，主要目的是在引入新类别时，由于标注成本高、数据稀缺，模型能够通过少量样本或零样本数据学习到新实体类别的特征。同时，通过结合伪标签生成与数据增强的方法，扩展现有的训练数据，从而进一步提高模型在少样本条件下的泛化能力。</p>
<h3 id="3-3-2-知识蒸馏">3.3.2 知识蒸馏</h3>
<p>知识蒸馏（Knowledge Distillation）是一种将复杂模型（教师模型）的知识传递给更简单模型（学生模型）的方法。在类增量学习中，知识蒸馏的作用是通过将旧模型的知识传递到新模型，防止新模型在学习新类别时遗忘之前的类别知识。</p>
<p>在本文中，知识蒸馏被用于缓解类增量NER中的灾难性遗忘问题。通过对旧类别的知识进行蒸馏，使新模型能够在学习新类别时，仍然保持对旧类别的识别能力。这一过程通过引入额外的损失函数，强制新模型的输出与旧模型一致，从而减少旧类别的知识遗忘。特别是在少样本条件下，知识蒸馏不仅有助于保持旧类别的记忆，还能帮助模型更有效地利用新类别的有限数据。</p>
<p>针对<strong>灾难性遗忘问题</strong>，知识蒸馏是解决灾难性遗忘的核心方法之一，通过在模型训练时保留旧类别的知识，防止新类别学习时的知识覆盖；针对<strong>标签不完整问题</strong>，通过蒸馏旧类别的知识，模型在新数据缺少旧类别标签的情况下，也能维持对旧类别的较高识别能力。</p>
<h3 id="3-3-3-合成数据增强">3.3.3 合成数据增强</h3>
<p>合成数据增强（Synthetic Data Augmentation）是通过生成合成样本来扩展训练数据集的一种技术，通常用于应对数据稀缺和类别不平衡问题。合成数据增强通过训练生成模型（如LSTM或GPT）生成与原始数据分布类似的合成数据，并将其用于训练，以提高模型的泛化能力。</p>
<p>本文中合成数据增强主要用于少样本条件下的数据扩展和类别平衡。通过生成未标注的上下文或样本，模型可以在没有大量标注数据的情况下继续学习新类别的特征。这种方法不仅增加了新类别的样本数量，也使得模型对新类别的学习更加全面，进而减轻类别不平衡带来的影响。</p>
<p>针对<strong>类别不平衡问题</strong>，合成数据增强通过生成更多的新类别数据，弥补了数据不平衡的现象，使模型在训练时不会偏向旧类别；针对<strong>少样本学习问题</strong>，通过合成与新类别相关的上下文数据，模型可以在数据不足的情况下进行更充分的学习，提升对新类别的识别能力。</p>
<h3 id="3-3-4-标签解释学习">3.3.4 标签解释学习</h3>
<p>标签解释学习方法适用于解决少样本命名实体识别中的泛化问题。为了应对少样本NER面临的仅凭少量的标注数据，模型很难准确识别和分类新的命名实体这一挑战，该方法通过在模型训练过程中引入多样化的实体类型及其详细的自然语言描述，使模型能够更好地理解和泛化未见过的实体类型。</p>
<p>在训练阶段，模型学习和理解这些标签的语义，然后在少量示例的情况下，将所学知识应用于识别和分类新的实体类型，提升模型的跨域和跨语言泛化能力，使其能够在未见过的领域或语言环境中依然表现出色，有效应对少样本条件下的NER任务。</p>
<h3 id="3-3-5-伪标签生成">3.3.5 伪标签生成</h3>
<p>伪标签生成（Pseudo-labeling）是一种半监督学习方法，基本思路是利用现有模型预测未标注数据的标签，生成伪标签，并将这些带有伪标签的数据加入到训练集中，从而扩展数据集规模。</p>
<p>本文利用伪标签生成方法扩展少样本数据集，特别是在新实体类别数据稀缺的情况下。通过使用已训练模型预测未标注数据中的实体类别，将生成的伪标签与真实标注的数据混合使用，增强模型对新类别的泛化能力。这样可以有效缓解类增量NER中由于数据不足带来的问题。</p>
<p>针对<strong>少样本学习问题</strong>，伪标签生成通过在新类别上生成更多带伪标签的数据，扩大了数据集的规模，有效提高了模型在少样本条件下的学习能力；针对<strong>标签不完整问题</strong>，当新数据缺少部分实体类别的标注时，伪标签生成可以补全这些缺失的标签，从而提高模型的学习效果。</p>
<h3 id="3-3-6-学习与回顾（L-R）">3.3.6 学习与回顾（L&amp;R）</h3>
<p>通过模拟人类通过不断复习旧知识来加深记忆的机制，在每个增量学习阶段结束后，通过回顾旧类别的知识，帮助模型保持对旧类别的认知。在学习新类别数据之后，模型会在增强后的数据集上进行再次训练，以重新强化对旧类别的记忆。</p>
<p>学习与回顾（L&amp;R）策略不仅通过系统的复习和强化训练缓解了灾难性遗忘问题，还通过丰富的训练数据支持了少样本学习的有效性。这种结合使得模型在增量学习过程中更加灵活和稳健，能够在新旧类别之间实现良好的平衡。</p>
<h2 id="3-4-理论方法总结">3.4 理论方法总结</h2>
<p>本文提出了一种综合知识蒸馏、伪标签生成、合成数据增强和L&amp;R的类增量NER方法，重点解决类增量NER任务中的灾难性遗忘和少样本学习问题。</p>
<p>具体而言，模型在每个增量阶段的学习过程中，首先通过<strong>知识蒸馏</strong>保持对旧类别的认知，避免灾难性遗忘；然后使用<strong>伪标签生成</strong>来扩展少量的新类别数据，增加数据规模；最后，通过<strong>合成数据增强</strong>进一步增加数据集的多样性和数量，缓解类别不平衡及少样本问题。</p>
<p>四. 研究方法设计思路的修改</p>
<ol>
<li>
<p><strong>引入人脑学习机制的类比</strong>：</p>
<ul>
<li>增强设计思路的阐述，结合人脑学习机制，提升理论高度。通过说明不同策略如何从不同角度缓解灾难性遗忘，进一步提高该段内容的深度。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>我们的方法设计基于人脑的学习机制：知识蒸馏类似于人类在学习新信息时通过复习巩固旧知识，而伪标签生成和L&amp;R策略则像人类在新情境下通过联想和类比进行推理和归纳，从而提高对新知识的记忆和泛化能力。</p>
</blockquote>
</li>
<li>
<p><strong>解释各策略的作用</strong>：</p>
<ul>
<li>详细说明不同策略（L&amp;R、伪标签生成、数据增强）是如何从不同角度缓解灾难性遗忘问题的。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>我们在知识蒸馏的基础上，分别通过L&amp;R策略复习旧类别的知识，通过伪标签生成扩展少样本数据集，通过合成数据增强整体数据的丰富性。每种策略都从不同角度针对灾难性遗忘进行缓解，确保模型在引入新类别时保持对旧类别的认知。</p>
</blockquote>
</li>
</ol>
<h1>4. 研究方法</h1>
<p>通过结合<strong>人脑学习机制的类比</strong>，我们提出了一种基于<strong>少样本条件下的类增量NER方法</strong>。该方法的核心思想是从人类学习的过程汲取灵感，设计多种策略以缓解类增量学习中的<strong>灾难性遗忘</strong>、<strong>少样本学习</strong>、<strong>标签不完整</strong>及<strong>类别不平衡</strong>等问题。我们使用了<strong>知识蒸馏</strong>、<strong>伪标签生成</strong>、<strong>合成数据增强</strong>和**学习与回顾（L&amp;R）**策略，以确保模型在逐步引入新类别时，能够同时保留旧类别的知识，且在少样本条件下具备较好的泛化能力。</p>
<h2 id="4-1-人脑学习机制">4.1 <strong>人脑学习机制</strong></h2>
<p>人类学习新知识时通常依赖于复习旧知识、推理和联想，以及构建假设场景来提升记忆和理解能力。类比于此，我们的方法设计通过以下几个方面模拟了人脑学习的过程：</p>
<ul>
<li><strong>知识蒸馏</strong>：这一策略类似于人类在学习新知识时通过不断复习来巩固已学知识。通过知识蒸馏，我们将旧模型的知识传递给新模型，确保新模型在学习新类别的同时，不会遗忘旧类别。就像人类通过复习保持对旧知识的记忆一样，知识蒸馏使得模型在新旧类别的学习中达到平衡。</li>
<li><strong>伪标签生成</strong>：伪标签生成则类似于人类通过联想和推理在不完全信息的情况下进行推测。当人类面对不确定的情境时，往往通过联想和类比做出预测和判断。伪标签生成通过已训练模型预测未标注数据中的实体类别，扩展数据集，帮助模型在少样本或零样本条件下提升对新类别的识别能力。</li>
<li><strong>学习与回顾（L&amp;R）策略</strong>：L&amp;R策略模拟了人类通过反复回顾来提升记忆的过程。人类在学习新知识时，通常通过回顾之前学过的内容来增强记忆和理解。L&amp;R策略在训练过程中，通过回顾旧类别的知识，帮助模型保持对旧类别的认知，并确保新旧类别的平衡。</li>
</ul>
<p>本文提出了在<strong>少样本条件下的类增量NER方法</strong>，旨在解决类增量NER任务中的<strong>灾难性遗忘</strong>、<strong>少样本学习</strong>、<strong>标签不完整</strong>及<strong>类别不平衡</strong>等问题。我们的研究方法主要包括三个核心步骤：知识蒸馏（Knowledge Distillation）、伪标签生成（Pseudo-labeling）和合成数据增强（Synthetic Data Augmentation），并在这些方法的基础上结合**学习与回顾（Learn &amp; Review, L&amp;R）**框架，逐步构建类增量NER模型。</p>
<h2 id="4-2-框架设计">4.2 <strong>框架设计</strong></h2>
<p>为了验证我们所提出方法的有效性，本文使用了一个分步的增量学习框架。在每一阶段中，模型将逐步接触新的实体类别，并学习在少量标注数据或零样本情况下识别新类别。同时，在不访问旧类别数据的前提下，模型通过知识蒸馏、伪标签生成和合成数据增强技术，缓解对旧类别的遗忘。</p>
<p>核心思想是通过多步训练和逐步引入新类别，使模型具备类增量学习的能力，并能够在每次学习新类别时保持对旧类别的记忆能力，尤其在少样本条件下提升模型的泛化性能。</p>
<p>为了解决类增量NER任务中的核心问题，特别是灾难性遗忘和少样本学习，本研究设计了以下几种方法：</p>
<h3 id="4-2-1知识蒸馏">4.2.1<strong>知识蒸馏</strong></h3>
<p>知识蒸馏的核心作用是<strong>缓解灾难性遗忘</strong>。通过将旧模型对旧类别的知识蒸馏给新模型，使新模型能够在学习新类别的同时，保留对旧类别的记忆。蒸馏过程确保了新模型输出与旧模型在旧类别上的输出保持一致，从而避免了新知识覆盖旧知识的情况。通过这种方法，模型能够有效地在逐步引入新类别的过程中保留旧类别的识别能力。</p>
<p>训练过程中，旧模型的输出（即对旧类别的预测分布）被用作教师模型。新模型通过优化目标函数，使其在学习新类别的同时，保持输出与旧模型对旧类别的预测相一致。</p>
<p>损失函数包含两部分：一是用于学习新类别的标准交叉熵损失，二是用于保持旧类别知识的蒸馏损失，后者通过缩小新旧模型在旧类别上的预测差异来实现。</p>
<p>对于每一个新类别的学习，模型的总损失函数为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>L</mi><mrow><mi mathvariant="normal">n</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">w</mi></mrow></msub><mo>+</mo><mi>λ</mi><mo>⋅</mo><msub><mi>L</mi><mrow><mi mathvariant="normal">d</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L=L_\mathrm{new}+\lambda\cdot L_\mathrm{distill}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.01389em;">new</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">distill</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">n</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_\mathrm{new}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.01389em;">new</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是针对新类别的标准交叉熵损失，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">d</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_\mathrm{distill}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">distill</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是针对旧类别知识的蒸馏损失，λ 是平衡这两者的系数。</p>
<p>通过知识蒸馏，模型可以有效保持旧模型对旧类别的识别能力，在学习新类的同时保留旧类的特性，可以很好地缓解由于安全性或存储问题使得数据对模型不可见导致的灾难性遗忘问题。</p>
<h3 id="4-2-2-合成数据增强">4.2.2 <strong>合成数据增强</strong></h3>
<p>合成数据增强通过生成与新类别相关的合成样本来解决<strong>类别不平衡和少样本学习问题</strong>。通过LSTM生成式模型生成与新类别相关的未标注上下文或样本，将这些合成数据添加到训练集中，使得模型能够接触到更多的新类别样本，从而平衡新旧类别的数据分布。这种方法类比于人类在理解新知识时，构建假设场景进行模拟学习，从而提升记忆和理解能力。</p>
<p>本文我们训练一个LSTM生成模型，旨在生成与新类别相关的未标注上下文或样本。通过训练LSTM模型，我们能够捕捉到数据集中的潜在模式，从而生成符合原始数据分布的合成文本。这些文本中包含与新类别相关的实体。而后将这些合成样本与真实标注数据和伪标签数据结合，形成增强后的训练集。最后使用包含合成数据的训练集，进一步训练当前模型，提高模型对新类别的适应能力。</p>
<p>首先，使用原始数据集进行LSTM模型的训练。通过大量的历史上下文数据，LSTM能够学习到不同实体类别的特征和相互关系。训练完成后，LSTM模型能够生成与新类别相关的文本。这些合成文本将包含新类别的实体，从而扩展模型的训练样本。</p>
<p>通过LSTM模型生成的未标注数据：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>D</mi><mtext>synthetic</mtext></msub><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>synthetic</mtext></msub><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">D_{\text{synthetic}}=\{(x_{\text{synthetic}})\}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">synthetic</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mopen">{(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">synthetic</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)}</span></span></span></span></span></p>
<p>在生成合成样本后，我们将这些合成数据与真实标注数据和伪标签数据结合，形成增强后的训练集：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>D</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><msub><mi>D</mi><mtext>labeled</mtext></msub><mo>∪</mo><msub><mi>D</mi><mtext>synthetic</mtext></msub></mrow><annotation encoding="application/x-tex">D^{\prime}=D_\text{labeled}\cup D_\text{synthetic}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8019em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">labeled</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">synthetic</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mtext>labeled</mtext></msub></mrow><annotation encoding="application/x-tex">D_\text{labeled}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">labeled</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是真实标注数据集,$ D_\text{synthetic}$是生成的文本数据。</p>
<p>针对类别不平衡问题，合成数据增强通过生成更多的新类别样本，有效缓解了类别不平衡的问题。新类别的合成样本数量显著增加，使得模型在训练时不至于过于偏向于旧类别，确保每个类别都能得到足够的关注，这种平衡的训练数据分布促使模型能够更好地学习新类别的特征，提升对各类别的识别能力。</p>
<p>针对少样本学习问题，合成数据的生成为新类别提供了额外的样本支持。即使在标注数据稀缺的情况下，生成的合成样本依然能够帮助模型学习到新类别的有效特征。通过构建与新类别相关的上下文数据，模型能够在数据不足的情况下进行更充分的学习，提升对新类别的识别能力。这一过程类似于人类在理解新知识时，通过构建假设场景进行模拟学习，从而增强记忆和理解能力。</p>
<h3 id="4-2-3-标签解释学习">4.2.3 标签解释学习</h3>
<p>少样本命名实体识别通过学习样本中被标注的实体来训练模型，标签解释学习在于充分利用每个实体的标签信息，把传统模型应用的标签（如“PER”）进行解释扩充，通过学习和解释实体类型的自然语言描述（即标签的描述信息），在只有少量标注数据的情况下提高NER模型的泛化能力和性能。</p>
<p>首先，模型通过学习现有实体类型的自然语言描述来掌握如何识别和分类文本中的命名实体。具体来说，模型在一个NER标注数据集上进行训练，该数据集中包括了一组实体类型及其对应的描述。例如，“PER”标签可能对应描述为“person entity”，“船”标签可能对应描述为“水面上移动的交通工具”。模型通过这些描述来建立标签与其含义之间的关联，从而学会识别和分类这些实体类型。</p>
<p>然后，将模型应用于新的、未见过的实体类型。通过提供新的实体类型描述和少量标注示例，模型能够在少样本条件下执行NER任务。在此阶段，模型可以利用先前学到的标签解释知识，将新的实体类型描述映射到相应的NER任务中。这一过程允许模型在未见过的领域或实体类型上快速适应并进行命名实体识别。</p>
<p>通过增加标签解释学习阶段中实体类型的多样性和描述的详细程度，能够显著提升模型在少样本条件下的NER性能，尤其是在未见过的领域和跨语言环境中。通过这种数据驱动的启发式优化，模型在少样本NER任务中的表现得到了显著改善。</p>
<h3 id="4-2-4-伪标签生成">4.2.4 <strong>伪标签生成</strong></h3>
<p>伪标签生成通过预测未标注数据中的实体类别并为其生成伪标签，扩大数据集规模。模型会使用前一阶段训练好的模型来预测新类别数据的伪标签，并将这些伪标签数据与少量标注数据混合，作为当前阶段的训练集。这种方法特别适用于少样本或零样本的场景，类似于人类通过联想和推理进行推测，伪标签生成为模型提供了额外的数据资源，扩展了训练集规模。</p>
<p>针对新类别的少量标注数据，首先使用前一阶段的模型$ M_{k-1}$预测未标注数据中的潜在实体，并生成伪标签。给定输入数据 x，模型预测的伪标签 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> 表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>D</mi><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">o</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>∣</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><msub><mi>M</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">D_{\mathrm{pseudo}}=\{(x,\hat{y})\mid\hat{y}=M_{k-1}(x)\}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">pseudo</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)}</span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mtext>pseudo</mtext></msub></mrow><annotation encoding="application/x-tex">D_\text{pseudo}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">pseudo</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>是伪标签数据，包含了未标注样本及其对应的伪标签。</p>
<p>而后将伪标签数据与真实标注数据结合，形成增强版的训练集<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>D</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">D^{\prime\prime}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span></span></span></span>。训练模型时，使用伪标签扩展数据集，结合标注数据集<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mtext>labeled</mtext></msub></mrow><annotation encoding="application/x-tex">D_\text{labeled}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">labeled</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>升模型对新类别的识别能力。构建增强后的数据集<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>D</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">D^{\prime\prime}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span></span></span></span>:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>D</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo>=</mo><msub><mi>D</mi><mtext>labeled</mtext></msub><mo>∪</mo><msub><mi>D</mi><mtext>pseudo</mtext></msub></mrow><annotation encoding="application/x-tex">D^{\prime\prime}=D_{\text{labeled}}\cup D_{\text{pseudo}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8019em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">labeled</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">pseudo</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>使用增强后数据集训练新的模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">M_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，使得模型能够接触到新类别的多种表示方式。</p>
<p>在训练过程中，损失函数应同时考虑真实标注数据和伪标签数据的贡献。损失函数为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>L</mi><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">d</mi></mrow></msub><mo>+</mo><mi>α</mi><msub><mi>L</mi><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">o</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L=L_{\mathrm{labeled}}+\alpha L_{\mathrm{pseudo}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">labeled</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">pseudo</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{\mathrm{labeled}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">labeled</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是针对真实标注数据的损失，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">o</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{\mathrm{pseudo}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">pseudo</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>是针对伪标签数据的损失,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>为超参数，确保模型不仅从标注数据中学习，还能从生成的伪标签中获取有价值的信息。</p>
<p>伪标签生成通过生成额外的伪标注数据，极大扩展了可供训练的数据集，帮助模型在数据稀缺的情况下学习新类别的特征。这种方法使得即使在少量标注样本的情况下，模型也能获得更多的训练数据，提升对新类别的识别能力。同时有效填补了数据集中未标注部分，确保模型在学习新类别时能够更全面地学习到不同的特征。这种填补使得模型可以在有限的标注数据下，更好地捕捉新类别的多样性。</p>
<h3 id="4-2-5-学习与回顾">4.2.5 <strong>学习与回顾</strong></h3>
<p>L&amp;R策略通过模仿人类的复习过程，基于<strong>回顾旧知识</strong>的增量学习策略。在每一阶段的学习过程中，模型不仅学习新类别的数据，通过定期回顾旧类别的数据或知识进行“复习”。这种策略通过在回顾阶段使用合成数据和伪标签数据，帮助模型保持对旧类别的记忆，确保模型在引入新类别时仍然能够正确识别旧类别。在本文中，L&amp;R策略与知识蒸馏、伪标签生成和合成数据增强相结合，提升了模型对新类别和旧类别的适应能力。</p>
<p>模型训练可以分为两个阶段：</p>
<p>1.<strong>学习阶段</strong>：模型首先在当前阶段的新类别数据上进行训练，并通过知识蒸馏学习旧类别的知识。训练目标是使模型尽可能准确地学习新类别，并通过引入<strong>蒸馏损失函数</strong>来保持对旧类别的记忆。</p>
<p>学习阶段的损失函数为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">t</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi></mrow></msub><mo>=</mo><msub><mi>L</mi><mrow><mi mathvariant="normal">n</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">w</mi></mrow></msub><mo>+</mo><mi>λ</mi><mo>⋅</mo><msub><mi>L</mi><mrow><mi mathvariant="normal">d</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_\mathrm{total}=L_\mathrm{new}+\lambda\cdot L_\mathrm{distill}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">total</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.01389em;">new</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">distill</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">n</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_\mathrm{new}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.01389em;">new</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示新类别的交叉熵损失，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">d</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_\mathrm{distill}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">distill</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示旧模型（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">M_{k-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>）与当前模型（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">M_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）之间的蒸馏损失，λ是平衡新知识学习与旧知识保留的权重。</p>
<p>2.<strong>回顾阶段</strong>：在学习完新类别后，L&amp;R策略通过合成数据增强和伪标签生成，构建一个更为丰富的训练集，帮助模型复习旧类别的知识。</p>
<p>增强的数据集包括两部分：合成数据和伪标签数据。通过LSTM生成模型生成的未标注上下文合成数据，使得模型在接触到新类别的同时，也能重新接触到旧类别的上下文信息。同时使用现有模型预测的未标注数据，生成带有伪标签的旧类别数据，扩大旧类别数据集规模。</p>
<p>回顾阶段的损失函数为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">v</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">w</mi></mrow></msub><mo>=</mo><msub><mi>L</mi><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">d</mi></mrow></msub><mo>+</mo><mi>α</mi><mo>⋅</mo><msub><mi>L</mi><mtext>distill-old</mtext></msub></mrow><annotation encoding="application/x-tex">L_{\mathrm{review}}=L_{\mathrm{augmented}}+\alpha\cdot L_{\text{distill-old}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.01389em;">review</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">augmented</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">distill-old</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mtext>augmented</mtext></msub></mrow><annotation encoding="application/x-tex">L_{\text{augmented}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">augmented</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>在增强数据集<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>D</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">D^{\prime\prime}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span></span></span></span>上计算的损失，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mtext>distill-old</mtext></msub></mrow><annotation encoding="application/x-tex">L_{\text{distill-old}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">distill-old</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是基于旧类别的蒸馏损失，α是权衡回顾损失和蒸馏损失的超参数。</p>
<p>通过回顾旧知识，模拟人类的学习行为，不仅依赖于知识蒸馏，还通过直接复习旧类别的数据，主动学习强化对旧类别的记忆，并减少新类别学习过程中旧知识的丢失。</p>
<h2 id="4-3-创新点">4.3 <strong>创新点</strong></h2>
<p>本文的方法设计通过模拟人脑的学习机制，主要从两方面解决类增量NER中的主要问题，设计思路和创新点包括：</p>
<ol>
<li><strong>从不同角度缓解灾难性遗忘</strong>：</li>
</ol>
<ul>
<li><strong>知识蒸馏</strong>通过传递旧类别的知识，有效防止新知识覆盖旧知识，确保模型在学习新类别时，不会遗忘旧类别。</li>
<li><strong>L&amp;R策略</strong>通过复习旧类别知识，进一步强化模型对旧类别的记忆，避免模型在增量学习过程中丧失对旧类别的识别能力。</li>
</ul>
<ol start="2">
<li><strong>提升少样本学习的泛化能力</strong>：</li>
</ol>
<ul>
<li><strong>伪标签生成</strong>通过在少样本条件下生成伪标注数据，扩展了新类别的数据集，帮助模型在标注数据不足的情况下，提升对新类别的学习效果。</li>
<li><strong>合成数据增强</strong>则通过生成更多的合成样本，有效缓解了类别不平衡和少样本问题，使模型能够接触到更多的训练数据，提升对新类别的泛化能力。</li>
</ul>
<p>本文的<strong>创新点</strong>在于通过结合多种策略，模拟人类的学习与记忆机制，提出了一种适用于少样本场景下的类增量NER解决方案，有效缓解了类增量NER中的灾难性遗忘和少样本问题。相比于传统方法，我们的综合训练方法在少样本和零样本条件下表现更为优越，不仅从理论上提升了模型对新旧类别的平衡能力，在实践中也展现出较强的适应性，能够在数据稀缺的情况下保持对新类别的良好学习效果，解决了实际应用中常见的数据稀缺和标签不完整的问题，具有重要的实践价值。</p>
<p>五.实验设计</p>
<p>（标签解释学习——这个应该要加进去我觉得，虽然我们并没有用这个，加一句由LearningO论文有力证明，该方法可通过迁移学习有效缓解类间混淆问题，而不会带来严重的负影响，故我们在所有方法都加入标签解释学习方法，而后对其他方法采用控制变量的方法进行实验。）</p>
<ol>
<li>
<p><strong>标签解释学习作为增强策略</strong>：</p>
<ul>
<li>在标签解释学习部分，强调其与知识蒸馏的结合，作为增强型策略应用于类增量NER。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>标签解释学习可以作为知识蒸馏的增强策略，通过使用标签的语义进行迁移学习，使模型能够更好地理解和区分新类别。</p>
</blockquote>
</li>
</ol>
<p>六. related work &amp; 文献引用的逻辑组织</p>
<ol>
<li>
<p><strong>调整文献引用的顺序和逻辑</strong>：</p>
<ul>
<li>文献引用部分需要根据实际论述的逻辑顺序进行重新组织，避免文献堆砌，确保每一篇文献的引用都能够自然引出后续的论点和讨论。</li>
</ul>
<p><strong>修改示例</strong>：</p>
<blockquote>
<p>相关工作引用部分，可以按照知识蒸馏、L&amp;R、伪标签生成、数据增强等方法的提出与演进顺序组织文献，确保逻辑连贯。</p>
</blockquote>
</li>
</ol>
<p>大致描述一下我们参考了这些文献的哪些部分（训练的方法），相当于说把这5个主要方法总结一下，每个总结记得提及对应的文献们，同时3、4节相应位置给一个文献引用的标注即可。第二节部分的问题浅浅看着标，有文献提到相关问题或解决相关问题就标注一下。</p>
<p>主要参考文献来着那四个论文+景士玲参考的论文+伪标签的论文+存在问题的论文</p>
<h1>5 Experiment Setup</h1>
<h2 id="5-1-dataset">5.1 dataset</h2>
<p>Following the previous work of NER class-incremental learning (Monaikul et al., 2021), in order to adapt to the Chinese context, we choose the Chinese military dataset as our experimental dataset. This dataset contains six entity classes, we randomly choose five ordering of enitity classes to do the experiment. Table 1 show the enitity classes used for each step.</p>
<table>
<thead>
<tr>
<th>Sequence</th>
</tr>
</thead>
<tbody>
<tr>
<td>S1:    1 -&gt; 2 -&gt; 3  -&gt; 4 -&gt; 5 -&gt; 6  S2:    2 -&gt; 4 -&gt; 6  -&gt; 1 -&gt; 3 -&gt; 5  S3:    6 -&gt; 2 -&gt; 1  -&gt; 5 -&gt; 4 -&gt; 3  S4:    3 -&gt; 6 -&gt; 5  -&gt; 2 -&gt; 4 -&gt; 1  S5:    5 -&gt; 6 -&gt; 2  -&gt; 1 -&gt; 3 -&gt; 4</td>
</tr>
</tbody>
</table>
<p><strong>Tabel1</strong></p>
<p>​          1：Armored Vehicle  2：Artillery    3：Missile</p>
<p>​                   4：Warship     5：Bomb    6：Space Equipment</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">奇冀</div><div class="post-copyright__author_desc">Hi~同行者</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://example.com/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2024/09/24/NER/理论部分/')">Few-Shot论文修改意见</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Few-Shot论文修改意见&amp;url=http://example.com/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/&amp;pic=/img/tu/img(28).jpg" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">奇冀の观猹录</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__category-list"><a class="post-meta__box__categoryes" href="/categories/NER/"><span class="categoryes-punctuation"> <i class="anzhiyufont anzhiyu-icon-inbox"></i></span>NER<span class="categoryesPageCount">19</span></a></div><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/NER/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>NER<span class="tagsPageCount">18</span></a></div></div><div class="post_share"><div class="social-share" data-image="/img/tu/img(43).jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/09/24/NER/%E8%AE%BA%E6%96%87%E5%88%9D%E7%A8%BF/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(12).jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Few-Shot论文</div></div></a></div><div class="next-post pull-right"><a href="/2024/10/02/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%AE%89%E8%A3%85MySQL/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(43).jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Linux系统配置安装MySQL</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2024/02/15/NER/BERT&Transformer/" title="BERT &amp; Transformer &amp; CRF"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(57).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-02-15</div><div class="title">BERT &amp; Transformer &amp; CRF</div></div></a></div><div><a href="/2024/04/24/NER/Few-Shot%E4%BB%A3%E7%A0%81/" title="Few-Shot代码"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(7).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-04-24</div><div class="title">Few-Shot代码</div></div></a></div><div><a href="/2024/04/24/NER/Few-shot%E4%BB%A3%E7%A0%81%E6%A2%B3%E7%90%86/" title="Few-shot代码梳理（粗略版）"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(35).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-04-24</div><div class="title">Few-shot代码梳理（粗略版）</div></div></a></div><div><a href="/2024/03/18/NER/O%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3/" title="Learning_O说明文档"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(97).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-03-18</div><div class="title">Learning_O说明文档</div></div></a></div><div><a href="/2024/03/18/NER/Learing_o/" title="Learning_O代码梳理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(48).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-03-18</div><div class="title">Learning_O代码梳理</div></div></a></div><div><a href="/2024/02/15/NER/RNN%E6%A8%A1%E5%9E%8B/" title="RNN模型"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(18).jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-02-15</div><div class="title">RNN模型</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-switch"><span class="first-comment">Valine</span><span id="switch-btn"></span><span class="second-comment">Twikoo</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="twikoo-wrap"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description"><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">这有关于<b style="color:#fff">产品、设计、开发</b>相关的问题和看法，还有<b style="color:#fff">文章翻译</b>和<b style="color:#fff">分享</b>。</div><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">相信你可以在这里找到对你有用的<b style="color:#fff">知识</b>和<b style="color:#fff">教程</b>。</div></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">奇冀</h1><div class="author-info__desc">Hi~同行者</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/Alive0103/Alive0103.github.io" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/1509553238?spm_id_from=333.1007.0.0" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来看我的博客鸭~希望对你有所帮助</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">1.发展现状</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1%E7%B1%BB%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.1.</span> <span class="toc-text">1. 1类增量学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-1-%E4%BC%A0%E7%BB%9F%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%BC%8F%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">2.1.1.</span> <span class="toc-text">1.1.1 传统学习方式的比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-2-NER%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.1.2.</span> <span class="toc-text">1.1.2 NER任务中的类增量学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E7%B1%BB%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%BC%93%E8%A7%A3%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 类增量学习中缓解灾难性遗忘的方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-%E4%BC%A0%E7%BB%9FNER%E4%B8%8E%E7%B1%BB%E5%A2%9E%E9%87%8FNER%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">2.3.</span> <span class="toc-text">1.3 传统NER与类增量NER的对比</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">2.存在的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98"><span class="toc-number">3.1.</span> <span class="toc-text">2.1 灾难性遗忘问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E6%A0%87%E7%AD%BE%E4%B8%8D%E5%AE%8C%E6%95%B4%E9%97%AE%E9%A2%98"><span class="toc-number">3.2.</span> <span class="toc-text">2.2 标签不完整问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%92%8C%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98"><span class="toc-number">3.3.</span> <span class="toc-text">2.3 类别不平衡和冲突问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-%E5%B0%91%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98"><span class="toc-number">3.4.</span> <span class="toc-text">2.4 少样本学习问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98"><span class="toc-number">3.5.</span> <span class="toc-text">2.5 过拟合问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">3.理论背景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E7%B1%BB%E5%A2%9E%E9%87%8FNER%E8%83%8C%E6%99%AF%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">4.1.</span> <span class="toc-text">3.1 类增量NER背景与挑战</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF"><span class="toc-number">4.2.</span> <span class="toc-text">3.2 解决思路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-%E7%90%86%E8%AE%BA%E6%A1%86%E6%9E%B6"><span class="toc-number">4.3.</span> <span class="toc-text">3.3 理论框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-1-%E5%B0%91%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0"><span class="toc-number">4.3.1.</span> <span class="toc-text">3.3.1 少样本学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-2-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F"><span class="toc-number">4.3.2.</span> <span class="toc-text">3.3.2 知识蒸馏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-3-%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">4.3.3.</span> <span class="toc-text">3.3.3 合成数据增强</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-4-%E6%A0%87%E7%AD%BE%E8%A7%A3%E9%87%8A%E5%AD%A6%E4%B9%A0"><span class="toc-number">4.3.4.</span> <span class="toc-text">3.3.4 标签解释学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-5-%E4%BC%AA%E6%A0%87%E7%AD%BE%E7%94%9F%E6%88%90"><span class="toc-number">4.3.5.</span> <span class="toc-text">3.3.5 伪标签生成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-6-%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%9B%9E%E9%A1%BE%EF%BC%88L-R%EF%BC%89"><span class="toc-number">4.3.6.</span> <span class="toc-text">3.3.6 学习与回顾（L&amp;R）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-%E7%90%86%E8%AE%BA%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93"><span class="toc-number">4.4.</span> <span class="toc-text">3.4 理论方法总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">4. 研究方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E4%BA%BA%E8%84%91%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%88%B6"><span class="toc-number">5.1.</span> <span class="toc-text">4.1 人脑学习机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1"><span class="toc-number">5.2.</span> <span class="toc-text">4.2 框架设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F"><span class="toc-number">5.2.1.</span> <span class="toc-text">4.2.1知识蒸馏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-2-%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">5.2.2.</span> <span class="toc-text">4.2.2 合成数据增强</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-3-%E6%A0%87%E7%AD%BE%E8%A7%A3%E9%87%8A%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.2.3.</span> <span class="toc-text">4.2.3 标签解释学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-4-%E4%BC%AA%E6%A0%87%E7%AD%BE%E7%94%9F%E6%88%90"><span class="toc-number">5.2.4.</span> <span class="toc-text">4.2.4 伪标签生成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-5-%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%9B%9E%E9%A1%BE"><span class="toc-number">5.2.5.</span> <span class="toc-text">4.2.5 学习与回顾</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">5.3.</span> <span class="toc-text">4.3 创新点</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">5 Experiment Setup</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-dataset"><span class="toc-number">6.1.</span> <span class="toc-text">5.1 dataset</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/10/02/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%AE%89%E8%A3%85MySQL/" title="Linux系统配置安装MySQL"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(43).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux系统配置安装MySQL"/></a><div class="content"><a class="title" href="/2024/10/02/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%AE%89%E8%A3%85MySQL/" title="Linux系统配置安装MySQL">Linux系统配置安装MySQL</a><time datetime="2024-10-01T16:00:00.000Z" title="发表于 2024-10-02 00:00:00">2024-10-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/" title="Few-Shot论文修改意见"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(28).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Few-Shot论文修改意见"/></a><div class="content"><a class="title" href="/2024/09/24/NER/%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86/" title="Few-Shot论文修改意见">Few-Shot论文修改意见</a><time datetime="2024-09-23T16:00:00.000Z" title="发表于 2024-09-24 00:00:00">2024-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/24/NER/%E8%AE%BA%E6%96%87%E5%88%9D%E7%A8%BF/" title="Few-Shot论文"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(12).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Few-Shot论文"/></a><div class="content"><a class="title" href="/2024/09/24/NER/%E8%AE%BA%E6%96%87%E5%88%9D%E7%A8%BF/" title="Few-Shot论文">Few-Shot论文</a><time datetime="2024-09-23T16:00:00.000Z" title="发表于 2024-09-24 00:00:00">2024-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/24/JAVA/JavaWeb/01_%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E6%A6%82%E8%BF%B0/" title="JavaWeb——WEB概述"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(28).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JavaWeb——WEB概述"/></a><div class="content"><a class="title" href="/2024/09/24/JAVA/JavaWeb/01_%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E6%A6%82%E8%BF%B0/" title="JavaWeb——WEB概述">JavaWeb——WEB概述</a><time datetime="2024-09-23T16:00:00.000Z" title="发表于 2024-09-24 00:00:00">2024-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/24/JAVA/JavaWeb/02_%E7%AC%AC%E4%BA%8C%E7%AB%A0%20HTML&amp;CSS/" title="JavaWeb——HTML&amp;CSS"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/tu/img(33).jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JavaWeb——HTML&amp;CSS"/></a><div class="content"><a class="title" href="/2024/09/24/JAVA/JavaWeb/02_%E7%AC%AC%E4%BA%8C%E7%AB%A0%20HTML&amp;CSS/" title="JavaWeb——HTML&amp;CSS">JavaWeb——HTML&amp;CSS</a><time datetime="2024-09-23T16:00:00.000Z" title="发表于 2024-09-24 00:00:00">2024-09-24</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer_deal"><a class="deal_link" href="/972477867@qq.com" title="email"><i class="anzhiyufont anzhiyu-icon-envelope"></i></a><img class="footer_mini_logo" title="返回顶部" alt="返回顶部" onclick="anzhiyu.scrollToDest(0, 500)" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a088b2d9c307b7e9f0e792.jpg" size="50px"/><a class="deal_link" target="_blank" rel="noopener" href="https://alive0103.github.io/" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://space.bilibili.com/372204786" title="Bilibili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div><div id="workboard"><img class="workSituationImg boardsign" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/66a07e38d9c307b7e9e81323.png" alt="欢迎来到我的小世界！~" title="欢迎来到我的小世界！~"/><div id="runtimeTextTip"></div></div><div id="anzhiyu-footer"><div class="footer-group"><div class="footer-title">服务</div><div class="footer-links"><a class="footer-item" title="51la统计" target="_blank" rel="noopener" href="https://v6.51.la/">51la统计</a><a class="footer-item" title="十年之约" target="_blank" rel="noopener" href="https://www.foreverblog.cn/">十年之约</a><a class="footer-item" title="开往" target="_blank" rel="noopener" href="https://github.com/travellings-link/travellings">开往</a></div></div><div class="footer-group"><div class="footer-title">导航</div><div class="footer-links"><a class="footer-item" title="Github" target="_blank" rel="noopener" href="https://github.com/Alive0103">Github</a><a class="footer-item" title="即刻短文" href="/essay/">即刻短文</a><a class="footer-item" title="友链文章" href="/fcircle/">友链文章</a><a class="footer-item" title="留言板" href="/comments/">留言板</a></div></div><div class="footer-group"><div class="footer-title-group"><div class="footer-title">友链</div><a class="random-friends-btn" id="footer-random-friends-btn" href="javascript:addFriendLinksInFooter();" title="换一批友情链接"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right"></i></a></div><div class="footer-links" id="friend-links-in-footer"></div></div></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title="博客框架为Hexo_v5.4.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Frame-Hexo.svg" alt="博客框架为Hexo_v5.4.0"/></a><a class="github-badge" target="_blank" href="https://blog.anheyu.com/" style="margin-inline:5px" data-title="本站使用AnZhiYu主题" title="本站使用AnZhiYu主题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.9/img/Theme-AnZhiYu-2E67D3.svg" alt="本站使用AnZhiYu主题"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2024 By <a class="footer-bar-link" href="/" title="奇冀" target="_blank">奇冀</a></div></div><div id="footer-type-tips"></div><div class="js-pjax"><script>function subtitleType () {
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      if (true) {
        const from = '出自 ' + data.from
        const sub = ["生活明朗&#44; 万物可爱&#44; 人间值得&#44; 未来可期."]
        sub.unshift(data.hitokoto, from)
        window.typed = new Typed('#footer-type-tips', {
          strings: sub,
          startDelay: 300,
          typeSpeed: 150,
          loop: true,
          backSpeed: 50,
        })
      } else {
        document.getElementById('footer-type-tips').innerHTML = data.hitokoto
      }
    })
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.cbd.int/typed.js@2.1.0/dist/typed.umd.js').then(subtitleType)
  }
} else {
  subtitleType()
}
</script></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a><a class="footer-bar-link" target="_blank" rel="noopener" href="https://7bu.top/" title="7bu图床">7bu图床</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">44</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">7</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/AssetsRepo" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/NLP-NER" title="智慧典藏(NLP-NER)"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="智慧典藏(NLP-NER)"/><span class="back-menu-item-text">智慧典藏(NLP-NER)</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/Alive0103/XDU-CS-lab" title="XDU-CS-lab"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="XDU-CS-lab"/><span class="back-menu-item-text">XDU-CS-lab</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于我</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/equipment/"><i class="anzhiyufont anzhiyu-icon-heartbeat faa-tada" style="font-size: 0.9em;"></i><span> 我的书屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Java/" style="font-size: 0.88rem; color: rgb(185, 32, 72);">Java<sup>5</sup></a><a href="/tags/JavaWeb/" style="font-size: 0.88rem; color: rgb(110, 46, 167);">JavaWeb<sup>8</sup></a><a href="/tags/MATLAB/" style="font-size: 0.88rem; color: rgb(27, 182, 142);">MATLAB<sup>1</sup></a><a href="/tags/NER/" style="font-size: 0.88rem; color: rgb(188, 53, 17);">NER<sup>18</sup></a><a href="/tags/anzhiyu/" style="font-size: 0.88rem; color: rgb(42, 47, 192);">anzhiyu<sup>1</sup></a><a href="/tags/pytorch/" style="font-size: 0.88rem; color: rgb(21, 59, 84);">pytorch<sup>1</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem; color: rgb(117, 103, 113);">算法<sup>4</sup></a><a href="/tags/%E8%A7%82%E7%8C%B9/" style="font-size: 0.88rem; color: rgb(8, 164, 63);">观猹<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%A7%91/" style="font-size: 0.88rem; color: rgb(173, 0, 12);">计科<sup>1</sup></a></div></div><hr/></div></div><div id="keyboard-tips"><div class="keyboardTitle">博客快捷键</div><div class="keybordList"><div class="keybordItem"><div class="keyGroup"><div class="key">shift K</div></div><div class="keyContent"><div class="content">关闭快捷键功能</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift A</div></div><div class="keyContent"><div class="content">打开/关闭中控台</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift M</div></div><div class="keyContent"><div class="content">播放/暂停音乐</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift D</div></div><div class="keyContent"><div class="content">深色/浅色显示模式</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift S</div></div><div class="keyContent"><div class="content">站内搜索</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift R</div></div><div class="keyContent"><div class="content">随机访问</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift H</div></div><div class="keyContent"><div class="content">返回首页</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift F</div></div><div class="keyContent"><div class="content">友链鱼塘</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift L</div></div><div class="keyContent"><div class="content">友链页面</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift P</div></div><div class="keyContent"><div class="content">关于本站</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift I</div></div><div class="keyContent"><div class="content">原版/本站右键菜单</div></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("16/02/2024 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2024 By 安知鱼 V1.6.12",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 奇冀 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script async="async">(function () {
  var grt = new Date("16/02/2024 00:00:00"); //设置网站上线时间
  var now = new Date();
  var dnum;
  var hnum;
  var mnum;
  var snum;
  var nowHour;

  // 计算并更新天数、小时数、分钟数和秒数
  function updateTime() {
    now = new Date(); // 更新 now 的值
    nowHour = now.getHours(); // 更新 nowHour 的值
    var days = (now - grt) / 1000 / 60 / 60 / 24;
    dnum = Math.floor(days);
    var hours = (now - grt) / 1000 / 60 / 60 - 24 * dnum;
    hnum = Math.floor(hours);
    if (String(hnum).length == 1) {
      hnum = "0" + hnum;
    }
    var minutes = (now - grt) / 1000 / 60 - 24 * 60 * dnum - 60 * hnum;
    mnum = Math.floor(minutes);
    if (String(mnum).length == 1) {
      mnum = "0" + mnum;
    }
    var seconds = (now - grt) / 1000 - 24 * 60 * 60 * dnum - 60 * 60 * hnum - 60 * mnum;
    snum = Math.round(seconds);
    if (String(snum).length == 1) {
      snum = "0" + snum;
    }
  }

  // 更新网页中显示的网站运行时间
  function updateHtml() {
    const footer = document.getElementById("footer");
    if (!footer) return
    let currentTimeHtml = "";
    if (nowHour < 18 && nowHour >= 9) {
      // 如果是上班时间，默认就是"安知鱼-上班摸鱼中.svg"图片，不需要更改
      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    } else {
      // 如果是下班时间，插入"安知鱼-下班啦.svg"图片
      let img = document.querySelector("#workboard .workSituationImg");
      if (img != null) {
        img.src = "https://pic.imgdb.cn/item/66a07e38d9c307b7e9e8134d.png";
        img.title = "下班了就该开开心心的玩耍";
        img.alt = "下班了就该开开心心的玩耍";
      }

      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    }

    if (document.getElementById("runtimeTextTip")) {
      document.getElementById("runtimeTextTip").innerHTML = currentTimeHtml;
    }
  }

  setInterval(() => {
    updateTime();
    updateHtml();
  }, 1000);
})();</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'pluRD6FBkCo5iajMaSIZPbZ8-gzGzoHsz',
      appKey: 'DEPAhIiN4akzk3dUFHvSzGL5',
      avatar: 'mp',
      serverURLs: 'https://plurd6fb.lc-cn-n1-shared.com',
      emojiMaps: {"tv_doge":"6ea59c827c414b4a2955fe79e0f6fd3dcd515e24.png","tv_亲亲":"a8111ad55953ef5e3be3327ef94eb4a39d535d06.png","tv_偷笑":"bb690d4107620f1c15cff29509db529a73aee261.png","tv_再见":"180129b8ea851044ce71caf55cc8ce44bd4a4fc8.png","tv_冷漠":"b9cbc755c2b3ee43be07ca13de84e5b699a3f101.png","tv_发怒":"34ba3cd204d5b05fec70ce08fa9fa0dd612409ff.png","tv_发财":"34db290afd2963723c6eb3c4560667db7253a21a.png","tv_可爱":"9e55fd9b500ac4b96613539f1ce2f9499e314ed9.png","tv_吐血":"09dd16a7aa59b77baa1155d47484409624470c77.png","tv_呆":"fe1179ebaa191569b0d31cecafe7a2cd1c951c9d.png","tv_呕吐":"9f996894a39e282ccf5e66856af49483f81870f3.png","tv_困":"241ee304e44c0af029adceb294399391e4737ef2.png","tv_坏笑":"1f0b87f731a671079842116e0991c91c2c88645a.png","tv_大佬":"093c1e2c490161aca397afc45573c877cdead616.png","tv_大哭":"23269aeb35f99daee28dda129676f6e9ea87934f.png","tv_委屈":"d04dba7b5465779e9755d2ab6f0a897b9b33bb77.png","tv_害羞":"a37683fb5642fa3ddfc7f4e5525fd13e42a2bdb1.png","tv_尴尬":"7cfa62dafc59798a3d3fb262d421eeeff166cfa4.png","tv_微笑":"70dc5c7b56f93eb61bddba11e28fb1d18fddcd4c.png","tv_思考":"90cf159733e558137ed20aa04d09964436f618a1.png","tv_惊吓":"0d15c7e2ee58e935adc6a7193ee042388adc22af.png"},
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.cbd.int/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.yydnas.cn/',
      region: 'ap-guangzhou',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.yydnas.cn/',
      region: 'ap-guangzhou',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  if ('Valine' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script src="https://cdn.cbd.int/blueimp-md5@2.19.0/js/md5.min.js"></script><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getIcon = (icon, mail) => {
    if (icon) return icon
    let defaultIcon = '?d=mp'
    let iconUrl = `https://gravatar.loli.net/avatar/${md5(mail.toLowerCase()) + defaultIcon}`
    return iconUrl
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const serverURL = 'https://plurd6fb.lc-cn-n1-shared.com'

    var settings = {
      "method": "GET",
      "headers": {
        "X-LC-Id": 'pluRD6FBkCo5iajMaSIZPbZ8-gzGzoHsz',
        "X-LC-Key": 'DEPAhIiN4akzk3dUFHvSzGL5',
        "Content-Type": "application/json"
      },
    }

    fetch(`${serverURL}/1.1/classes/Comment?limit=6&order=-createdAt`,settings)
      .then(response => response.json())
      .then(data => {
        const valineArray = data.results.map(function (e) {
          return {
            'avatar': getIcon(e.QQAvatar, e.mail),
            'content': changeContent(e.comment),
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.updatedAt,
          }
        })
        saveToLocal.set('valine-newest-comments', JSON.stringify(valineArray), 10/(60*24))
        generateHtml(valineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      }) 
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('valine-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "visitor@anheyu.com";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>